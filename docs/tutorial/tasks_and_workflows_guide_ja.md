# ã‚¿ã‚¹ã‚¯ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰

Graflowã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®å®Ÿè·µã‚¬ã‚¤ãƒ‰ â€” æœ€åˆã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰é«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã¾ã§ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€å®Ÿè·µçš„ãªä¾‹ã‚’é€šã˜ã¦ã‚¿ã‚¹ã‚¯ã®å®šç¾©ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

### ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ

| æ¦‚å¿µ | æ§‹æ–‡ | ç›®çš„ |
|---------|--------|---------|
| ã‚¿ã‚¹ã‚¯å®šç¾© | `@task` | é–¢æ•°ã‚’ã‚¿ã‚¹ã‚¯ã«å¤‰æ› |
| ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¹ã‚¯ID | `@task(task_id="id")` | ã‚¿ã‚¹ã‚¯è­˜åˆ¥å­ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š |
| ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä½œæˆ | `with workflow("name") as wf:` | ã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•ã‚’å®šç¾© |
| ç›´åˆ— | `task_a >> task_b` | ã‚¿ã‚¹ã‚¯ã‚’é †ç•ªã«å®Ÿè¡Œ |
| ä¸¦åˆ— | `task_a \| task_b` | ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å®Ÿè¡Œ |
| ã‚¿ã‚¹ã‚¯ã®é€£çµ | `chain(task_a, task_b, task_c)` | ç›´åˆ—ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ |
| ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ | `parallel(task_a, task_b, task_c)` | ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ |
| ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | `task(task_id="id", param=value)` | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ãã§æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ |
| ã‚°ãƒ«ãƒ¼ãƒ—åè¨­å®š | `task_group.set_group_name("name")` | ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã®åå‰ã‚’å¤‰æ›´ |
| å®Ÿè¡Œè¨­å®š | `task_group.with_execution(policy="...")` | ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œãƒãƒªã‚·ãƒ¼ã‚’è¨­å®š |
| ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ | `@task(inject_context=True)` | ãƒãƒ£ãƒ³ãƒãƒ«/ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã«ã‚¢ã‚¯ã‚»ã‚¹ |
| LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ³¨å…¥ | `@task(inject_llm_client=True)` | LLM APIã‚’ç›´æ¥å‘¼ã³å‡ºã— |
| LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ³¨å…¥ | `@task(inject_llm_agent="name")` | ãƒ„ãƒ¼ãƒ«ä»˜ãSuperAgentã‚’æ³¨å…¥ |
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆ | `PromptManagerFactory.create("yaml", ...)` | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒª |
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ | `ctx.prompt_manager` | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ |
| ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾— | `pm.get_text_prompt("name")` | ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾— |
| ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾— | `pm.get_chat_prompt("name")` | ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾— |
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° | `prompt.render(var=value)` | ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã‚’ç½®æ› |
| ãƒãƒ£ãƒ³ãƒãƒ«å–å¾— | `ctx.get_channel()` | ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ãƒãƒ£ãƒ³ãƒãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ |
| TTLä»˜ãä¿å­˜ | `channel.set(key, value, ttl=300)` | æœ‰åŠ¹æœŸé™ä»˜ãã§ä¿å­˜(ç§’) |
| ãƒªã‚¹ãƒˆæœ«å°¾ã«è¿½åŠ  | `channel.append(key, value)` | ãƒªã‚¹ãƒˆæœ«å°¾ã«è¿½åŠ  |
| ãƒªã‚¹ãƒˆå…ˆé ­ã«è¿½åŠ  | `channel.prepend(key, value)` | ãƒªã‚¹ãƒˆå…ˆé ­ã«è¿½åŠ  |
| å‹ä»˜ããƒãƒ£ãƒ³ãƒãƒ«å–å¾— | `ctx.get_typed_channel(Schema)` | å‹å®‰å…¨ãªãƒãƒ£ãƒ³ãƒãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ |
| ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¦æ±‚ | `ctx.request_feedback(...)` | HITLã«ã‚ˆã‚‹æ‰¿èª/å…¥åŠ› |
| åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | `wf.execute(initial_channel={...})` | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š |
| å…¨çµæœå–å¾— | `wf.execute(ret_context=True)` | ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯çµæœã«ã‚¢ã‚¯ã‚»ã‚¹ |
| ã‚¿ã‚¹ã‚¯çµæœå–å¾— | `ctx.get_result(task_id)` | ç‰¹å®šã‚¿ã‚¹ã‚¯ã®çµæœã‚’å–å¾— |
| ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã¸è¿½åŠ  | `ctx.next_task(task)` | ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—é€šå¸¸ã®å¾Œç¶šã¸ |
| ã‚¿ã‚¹ã‚¯ã¸ã‚¸ãƒ£ãƒ³ãƒ— | `ctx.next_task(task, goto=True)` | æ—¢å­˜ã‚¿ã‚¹ã‚¯ã¸ç§»å‹•ã—å¾Œç¶šã‚’ã‚¹ã‚­ãƒƒãƒ— |
| è‡ªå·±ãƒ«ãƒ¼ãƒ— | `ctx.next_iteration()` | ãƒªãƒˆãƒ©ã‚¤/åæŸãƒ‘ã‚¿ãƒ¼ãƒ³ |
| æ­£å¸¸çµ‚äº† | `ctx.terminate_workflow()` | æ­£å¸¸ã«çµ‚äº† |
| ã‚¨ãƒ©ãƒ¼çµ‚äº† | `ctx.cancel_workflow()` | ã‚¨ãƒ©ãƒ¼ã§çµ‚äº† |

---

## ç›®æ¬¡

**ã¯ã˜ã‚ã«**
- [ãƒ¬ãƒ™ãƒ«1: æœ€åˆã®ã‚¿ã‚¹ã‚¯](#ãƒ¬ãƒ™ãƒ«1-æœ€åˆã®ã‚¿ã‚¹ã‚¯) - @taskãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã¨ã‚¿ã‚¹ã‚¯ID
- [ãƒ¬ãƒ™ãƒ«2: æœ€åˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#ãƒ¬ãƒ™ãƒ«2-æœ€åˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼) - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å®Ÿè¡Œ
- [ãƒ¬ãƒ™ãƒ«3: ã‚¿ã‚¹ã‚¯åˆæˆ](#ãƒ¬ãƒ™ãƒ«3-ã‚¿ã‚¹ã‚¯åˆæˆ) - ç›´åˆ—(>>)ã¨ä¸¦åˆ—(|)æ¼”ç®—å­
- [ãƒ¬ãƒ™ãƒ«4: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å—ã‘æ¸¡ã—](#ãƒ¬ãƒ™ãƒ«4-ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å—ã‘æ¸¡ã—) - ãƒãƒ£ãƒ³ãƒãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒ‰

**ã‚³ã‚¢ã‚³ãƒ³ã‚»ãƒ—ãƒˆ**
- [ãƒ¬ãƒ™ãƒ«5: ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹](#ãƒ¬ãƒ™ãƒ«5-ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹) - ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†åˆ©ç”¨
- [ãƒ¬ãƒ™ãƒ«6: ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ](#ãƒ¬ãƒ™ãƒ«6-ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ) - ã‚¿ã‚¹ã‚¯é–“é€šä¿¡ã€æ³¨å…¥ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†
- [ãƒ¬ãƒ™ãƒ«7: å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³](#ãƒ¬ãƒ™ãƒ«7-å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³) - çµæœå–å¾—ã¨å®Ÿè¡Œåˆ¶å¾¡
- [ãƒ¬ãƒ™ãƒ«8: è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#ãƒ¬ãƒ™ãƒ«8-è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼) - ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

**é«˜åº¦ãªãƒˆãƒ”ãƒƒã‚¯**
- [ãƒ¬ãƒ™ãƒ«9: å‹•çš„ã‚¿ã‚¹ã‚¯ç”Ÿæˆ](#ãƒ¬ãƒ™ãƒ«9-å‹•çš„ã‚¿ã‚¹ã‚¯ç”Ÿæˆ) - å®Ÿè¡Œæ™‚ã®ã‚¿ã‚¹ã‚¯è¿½åŠ ã¨åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼

**ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹**
- [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)
- [ã¾ã¨ã‚](#ã¾ã¨ã‚)

---

## ã‚³ã‚¢ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

å§‹ã‚ã‚‹å‰ã«ã€ä¸»è¦ãªæ¦‚å¿µã‚’ç¢ºèªã—ã¾ã™:

- **ã‚¿ã‚¹ã‚¯**: ä½œæ¥­å˜ä½ ( `@task` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ä»˜ãã®Pythoné–¢æ•° )
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: ä¾å­˜é–¢ä¿‚ã‚’æŒã¤ã‚¿ã‚¹ã‚¯ã®é›†åˆ
- **ã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•**: ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé †åºã‚’è¡¨ã™æœ‰å‘ã‚°ãƒ©ãƒ•
- **å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**: å®Ÿè¡Œæ™‚ã®çŠ¶æ…‹ (ãƒãƒ£ãƒ³ãƒãƒ«ã€çµæœã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)

---

## ãƒ¬ãƒ™ãƒ«1: æœ€åˆã®ã‚¿ã‚¹ã‚¯

ã¾ãšã¯åŸºæœ¬ä¸­ã®åŸºæœ¬ã€`@task`ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‹ã‚‰å§‹ã‚ã¾ã™ã€‚

### @taskãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

ä»»æ„ã®Pythoné–¢æ•°ã‚’Graflowã‚¿ã‚¹ã‚¯ã«å¤‰æ›ã§ãã¾ã™:

```python
from graflow.core.decorators import task

@task
def hello():
    """A simple task."""
    print("Hello, Graflow!")
    return "success"
```

**ä½•ãŒèµ·ããŸã®ã‹?**
- `@task` ã«ã‚ˆã‚Šé€šå¸¸ã®é–¢æ•°ãŒGraflowã‚¿ã‚¹ã‚¯ã«ãªã‚Šã¾ã™
- ã‚¿ã‚¹ã‚¯ã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†…ã§ä½¿ã†ã“ã¨ã‚‚ç›´æ¥å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™

### ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¹ã‚¯ID

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯é–¢æ•°åãŒã‚¿ã‚¹ã‚¯IDã«ãªã‚Šã¾ã™ã€‚ã‚«ã‚¹ã‚¿ãƒ IDã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™:

```python
# Default: task_id is "hello"
@task
def hello():
    print("Hello!")

# Custom: task_id is "greeting_task"
@task(task_id="greeting_task")
def hello():
    print("Hello!")
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `@task` ã‚’ä½¿ã£ã¦ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® `task_id` ã¯é–¢æ•°å
- `@task(task_id="custom_id")` ã§æ˜ç¤ºçš„ã«å‘½å

### .run() ã§ã‚¿ã‚¹ã‚¯ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹

ã‚¿ã‚¹ã‚¯ã¯ `.run()` ã‚’ä½¿ã£ã¦ç›´æ¥å®Ÿè¡Œã—ã€ãƒ†ã‚¹ãƒˆã§ãã¾ã™:

```python
@task
def calculate(x: int, y: int) -> int:
    """Add two numbers."""
    return x + y

# Test the task directly
result = calculate.run(x=5, y=3)
print(result)  # Output: 8
```

**`.run()` ã‚’ä½¿ã†ã‚¿ã‚¤ãƒŸãƒ³ã‚°:**
- âœ… å˜ä½“ãƒ†ã‚¹ãƒˆã§ã‚¿ã‚¹ã‚¯ã‚’æ¤œè¨¼ã™ã‚‹
- âœ… ã‚¿ã‚¹ã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã®ã‚¯ã‚¤ãƒƒã‚¯æ¤œè¨¼
- âœ… ã‚¿ã‚¹ã‚¯æŒ™å‹•ã®ãƒ‡ãƒãƒƒã‚°
- âŒ æœ¬ç•ªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯ä½¿ç”¨ã—ãªã„ ( `workflow.execute()` ã‚’ä½¿ã† )

**ä¾‹: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ãã§ãƒ†ã‚¹ãƒˆ**

```python
@task
def process_data(data: list[int], multiplier: int = 2) -> list[int]:
    """Process data with a multiplier."""
    return [x * multiplier for x in data]

# Test with different parameters
result1 = process_data.run(data=[1, 2, 3])
print(result1)  # Output: [2, 4, 6]

result2 = process_data.run(data=[1, 2, 3], multiplier=3)
print(result2)  # Output: [3, 6, 9]
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:** `.run()` ã‚’ä½¿ã£ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æŠ•å…¥å‰ã«ã‚¿ã‚¹ã‚¯å˜ä½“ã§æ¤œè¨¼ã—ã¾ã—ã‚‡ã†ã€‚

---

## ãƒ¬ãƒ™ãƒ«2: æœ€åˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

æ¬¡ã«ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¤ãªã’ã¾ã™ã€‚

### å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹

```python
from graflow.core.workflow import workflow
from graflow.core.decorators import task

with workflow("simple_pipeline") as wf:
    @task
    def start():
        print("Starting!")

    @task
    def middle():
        print("Middle!")

    @task
    def end():
        print("Ending!")

    # Connect tasks: start â†’ middle â†’ end
    start >> middle >> end

    # Execute the workflow
    wf.execute()
```

**å‡ºåŠ›:**
```
Starting!
Middle!
Ending!
```

**ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹:**
- `with workflow("name")` ãŒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
- å†…éƒ¨ã§å®šç¾©ã—ãŸã‚¿ã‚¹ã‚¯ã¯è‡ªå‹•ç™»éŒ²ã•ã‚Œã¾ã™
- `>>` ãŒã‚¿ã‚¹ã‚¯ã‚’ç›´åˆ—ã«æ¥ç¶š (start â†’ middle â†’ end)
- `wf.execute()` ãŒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `with workflow("name")` ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œæˆ
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©
- `>>` ã§ç›´åˆ—æ¥ç¶š
- `wf.execute()` ã§å®Ÿè¡Œ

---

## ãƒ¬ãƒ™ãƒ«3: ã‚¿ã‚¹ã‚¯åˆæˆ

`>>` (ç›´åˆ—) ã¨ `|` (ä¸¦åˆ—) æ¼”ç®—å­ã‚’ä½¿ã£ãŸã‚¿ã‚¹ã‚¯ã®çµ„ã¿åˆã‚ã›ã‚’å­¦ã³ã¾ã™ã€‚

### ç›´åˆ—ã¨ä¸¦åˆ—ã®çµ„ã¿åˆã‚ã›

```python
with workflow("composition") as wf:
    @task
    def start():
        print("Start")

    @task
    def parallel_a():
        print("Parallel A")

    @task
    def parallel_b():
        print("Parallel B")

    @task
    def end():
        print("End")

    # Pattern: start â†’ (parallel_a | parallel_b) â†’ end
    start >> (parallel_a | parallel_b) >> end

    wf.execute()
```

**å®Ÿè¡Œãƒ•ãƒ­ãƒ¼:**
1. `start` ãŒæœ€åˆã«å®Ÿè¡Œã•ã‚Œã‚‹
2. `parallel_a` ã¨ `parallel_b` ãŒåŒæ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹
3. ä¸¦åˆ—ã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã« `end` ãŒå®Ÿè¡Œã•ã‚Œã‚‹

**å‡ºåŠ›:**
```
Start
Parallel A
Parallel B
End
```

**æ¼”ç®—å­:**
- `>>` ã¯ç›´åˆ—ä¾å­˜ (é †ç•ªã«å®Ÿè¡Œ)
- `|` ã¯ä¸¦åˆ—å®Ÿè¡Œ (åŒæ™‚ã«å®Ÿè¡Œ)
- ã‹ã£ã“ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–: `(task_a | task_b)`

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `task_a >> task_b` ã¯ã€Œaã®å¾Œã«bã‚’å®Ÿè¡Œã€
- `task_a | task_b` ã¯ã€Œaã¨bã‚’åŒæ™‚ã«å®Ÿè¡Œã€
- æ··åœ¨ãƒ‘ã‚¿ãƒ¼ãƒ³: `a >> (b | c) >> d`

### ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: chain() ã¨ parallel()

è¤‡æ•°ã‚¿ã‚¹ã‚¯ã®ç›´åˆ—/ä¸¦åˆ—ã‚’ä½œã‚‹å ´åˆã¯ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ãŒä¾¿åˆ©ã§ã™:

```python
from graflow.core.task import chain, parallel

with workflow("helpers") as wf:
    @task
    def task_a():
        print("A")

    @task
    def task_b():
        print("B")

    @task
    def task_c():
        print("C")

    @task
    def task_d():
        print("D")

    # Using chain(*tasks) - equivalent to task_a >> task_b >> task_c
    seq = chain(task_a, task_b, task_c)

    # Using parallel(*tasks) - equivalent to task_a | task_b | task_c
    par = parallel(task_a, task_b, task_c)

    # Combine them
    _pipeline = seq >> par

    wf.execute()
```

**é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£:**
- `chain(*tasks)` - 1å€‹ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹
- `parallel(*tasks)` - 2å€‹ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹

**ä½¿ã„åˆ†ã‘:**
- `chain(*tasks)`: 3ã¤ä»¥ä¸Šã®ç›´åˆ—æ¥ç¶šã§èª­ã¿ã‚„ã™ã„
- `parallel(*tasks)`: 3ã¤ä»¥ä¸Šã®ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã§èª­ã¿ã‚„ã™ã„
- æ¼”ç®—å­ (`>>`, `|`): 2ã‚¿ã‚¹ã‚¯ã‚„æ··åœ¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é©ã™ã‚‹

**ä¾‹: å‹•çš„ãªã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ**

```python
# If you have tasks in a list, unpack them with *
task_list = [task_a, task_b, task_c, task_d]

# Unpack the list into parallel()
parallel_group = parallel(*task_list)

# Or use operators in a loop
group = task_list[0]
for task in task_list[1:]:
    group = group | task
```

**ä¾‹: äº‹å‰ãƒã‚¤ãƒ³ãƒ‰ã—ãŸå¼•æ•° (ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹) ã®ä½¿ç”¨**

```python
@task
def fetch_weather(city: str) -> dict:
    return {"city": city, "temp": 20}

# Create task instances with bound parameters
tokyo = fetch_weather(task_id="tokyo", city="Tokyo")
paris = fetch_weather(task_id="paris", city="Paris")
london = fetch_weather(task_id="london", city="London")

with workflow("weather") as wf:
    # Use parallel() with task instances
    all_cities = parallel(tokyo, paris, london)

    wf.execute()
```

**ä¾‹: chain() ã¨ parallel() ã‚’ä½¿ã£ãŸå‹•çš„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹**

```python
@task
def process_batch(batch_id: int, data: list) -> dict:
    return {"batch_id": batch_id, "count": len(data)}

# Generate task instances dynamically
cities = ["Tokyo", "Paris", "London", "NYC"]
fetch_tasks = [
    fetch_weather(task_id=f"fetch_{city.lower()}", city=city)
    for city in cities
]

batches = [1, 2, 3]
process_tasks = [
    process_batch(task_id=f"batch_{i}", batch_id=i, data=[])
    for i in batches
]

with workflow("dynamic") as wf:
    # Use parallel() with task instances
    all_fetches = parallel(*fetch_tasks)

    # Use chain() with task instances
    all_batches = chain(*process_tasks)

    # Combine
    all_fetches >> all_batches

    wf.execute()
```

### ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã®è¨­å®š

ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã¯åå‰ã‚„å®Ÿè¡Œãƒãƒªã‚·ãƒ¼ã‚’è¨­å®šã§ãã¾ã™:

```python
with workflow("configured") as wf:
    @task
    def task_a():
        print("A")

    @task
    def task_b():
        print("B")

    @task
    def task_c():
        print("C")

    # Create parallel group with custom name
    group = (task_a | task_b | task_c).set_group_name("my_parallel_tasks")

    # Configure execution policy
    group.with_execution(policy="best_effort")  # Continue even if some tasks fail

    wf.execute()
```

**åˆ©ç”¨å¯èƒ½ãªå®Ÿè¡Œãƒãƒªã‚·ãƒ¼:**

| ãƒãƒªã‚·ãƒ¼ | æŒ™å‹• |
|--------|----------|
| `"strict"` (default) | ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯æˆåŠŸãŒå¿…é ˆã€‚å¤±æ•—ã™ã‚‹ã¨å…¨ä½“ãŒå¤±æ•— |
| `"best_effort"` | å¤±æ•—ã—ã¦ã‚‚ç¶™ç¶šã—ã€çµæœã‚’åé›† |
| `AtLeastNGroupPolicy(min_success=N)` | Nå€‹ä»¥ä¸Šã®æˆåŠŸãŒå¿…è¦ |
| `CriticalGroupPolicy(critical_task_ids=[...])` | æŒ‡å®šã‚¿ã‚¹ã‚¯ã®æˆåŠŸãŒå¿…é ˆ |

**ä¾‹: ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆã®ä¸¦åˆ—å®Ÿè¡Œ**

```python
# Continue workflow even if some parallel tasks fail
(fetch_api | fetch_db | fetch_cache).with_execution(policy="best_effort")
```

**ä¾‹: ã‚«ã‚¹ã‚¿ãƒ ã‚°ãƒ«ãƒ¼ãƒ—å**

```python
# Rename group for clarity in logs and visualization
parallel_fetches = (fetch_a | fetch_b | fetch_c).set_group_name("data_fetches")
```

**ä¾‹: é«˜åº¦ãªå®Ÿè¡Œè¨­å®š**

```python
from graflow.coordination.coordinator import CoordinationBackend

# Use threading backend with custom thread count
(task_a | task_b | task_c | task_d).with_execution(
    backend=CoordinationBackend.THREADING,
    backend_config={"thread_count": 2},
    policy="best_effort"
)

# AtLeastN policy: Require at least 3 out of 4 tasks to succeed
from graflow.core.handlers.group_policy import AtLeastNGroupPolicy

(task_a | task_b | task_c | task_d).with_execution(
    policy=AtLeastNGroupPolicy(min_success=3)
)

# Critical policy: Specific tasks must succeed
from graflow.core.handlers.group_policy import CriticalGroupPolicy

(task_a | task_b | task_c).with_execution(
    policy=CriticalGroupPolicy(critical_task_ids=["task_a", "task_b"])
)
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `chain()` ã¨ `parallel()` ã‚’ä½¿ã†ã¨å¤šã‚¿ã‚¹ã‚¯ä½œæˆãŒç°¡æ½”
- `.set_group_name()` ã§ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—ã«æ„å‘³ã®ã‚ã‚‹åå‰ã‚’ä»˜ã‘ã‚‹
- `.with_execution(policy=...)` ã§å¤±æ•—æ™‚ã®æ‰±ã„ã‚’åˆ¶å¾¡
- `backend` ã¨ `backend_config` ã§å®Ÿè¡Œãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’è¨­å®š

---

## ãƒ¬ãƒ™ãƒ«4: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å—ã‘æ¸¡ã—

ãƒãƒ£ãƒ³ãƒãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒ‰ã‚’ä½¿ã£ã¦ã‚¿ã‚¹ã‚¯é–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

### ãƒãƒ£ãƒ³ãƒãƒ«ã§ã‚¿ã‚¹ã‚¯é–“é€šä¿¡

ã‚¿ã‚¹ã‚¯ã¯å…±æœ‰ãƒãƒ£ãƒ³ãƒãƒ«ã‚’èª­ã¿æ›¸ãã—ã¦é€šä¿¡ã—ã¾ã™ (è©³ç´°ã¯[ãƒ¬ãƒ™ãƒ«6](#ãƒ¬ãƒ™ãƒ«6-ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ)):

```python
from graflow.core.context import TaskExecutionContext

with workflow("channel_communication") as wf:
    @task(inject_context=True)
    def producer(ctx: TaskExecutionContext):
        channel = ctx.get_channel()
        channel.set("user_id", "user_123")

    @task(inject_context=True)
    def consumer(ctx: TaskExecutionContext):
        channel = ctx.get_channel()
        user_id = channel.get("user_id")
        print(f"User: {user_id}")

    producer >> consumer
    wf.execute()
```

### éƒ¨åˆ†çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒ‰

ä¸€éƒ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¿ã‚¹ã‚¯ç”Ÿæˆæ™‚ã«ãƒã‚¤ãƒ³ãƒ‰ã—ã€æ®‹ã‚Šã¯ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å–å¾—ã§ãã¾ã™:

```python
with workflow("partial_binding") as wf:
    @task
    def calculate(base: int, multiplier: int, offset: int) -> int:
        result = base * multiplier + offset
        print(f"calculate: {base} * {multiplier} + {offset} = {result}")
        return result

    # Bind only 'base', others come from channel
    task_instance = calculate(task_id="calc", base=10)

    # Execute with channel values for multiplier and offset
    _, ctx = wf.execute(
        ret_context=True,
        initial_channel={"multiplier": 3, "offset": 5}
    )

    result = ctx.get_result("calc")
    print(f"Result: {result}")
```

**å‡ºåŠ›:**
```
calculate: 10 * 3 + 5 = 35
Result: 35
```

**ä½•ãŒèµ·ããŸã‹:**
- `base=10` ã¯ã‚¿ã‚¹ã‚¯ç”Ÿæˆæ™‚ã«ãƒã‚¤ãƒ³ãƒ‰ (æœ€å„ªå…ˆ)
- `multiplier=3` ã¨ `offset=5` ã¯ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å–å¾—
- ãƒã‚¤ãƒ³ãƒ‰æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒãƒ£ãƒ³ãƒãƒ«å€¤ã‚’ä¸Šæ›¸ã

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- ã‚¿ã‚¹ã‚¯ã¯ãƒãƒ£ãƒ³ãƒãƒ«çµŒç”±ã§é€šä¿¡å¯èƒ½ (è©³ç´°ã¯[ãƒ¬ãƒ™ãƒ«6](#ãƒ¬ãƒ™ãƒ«6-ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ))
- ä¸€éƒ¨ã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ã€æ®‹ã‚Šã‚’ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å–å¾—ã§ãã‚‹
- ãƒã‚¤ãƒ³ãƒ‰æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå„ªå…ˆã•ã‚Œã‚‹

---

## ãƒ¬ãƒ™ãƒ«5: ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

**Graflowã®æ–°æ©Ÿèƒ½**: 1ã¤ã®ã‚¿ã‚¹ã‚¯å®šç¾©ã‹ã‚‰è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã§ãã¾ã™ã€‚

### èª²é¡Œ

åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†åˆ©ç”¨ã—ãŸã„ã‚±ãƒ¼ã‚¹:

```python
# âŒ Without task instances (repetitive)
@task
def fetch_tokyo():
    return fetch("Tokyo")

@task
def fetch_paris():
    return fetch("Paris")
```

### è§£æ±ºç­–

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ãŸã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ:

```python
# âœ… With task instances (reusable)
@task
def fetch_weather(city: str) -> str:
    return f"Weather for {city}"

# Create instances with different parameters
tokyo = fetch_weather(task_id="tokyo", city="Tokyo")
paris = fetch_weather(task_id="paris", city="Paris")
london = fetch_weather(task_id="london", city="London")

with workflow("weather") as wf:
    # Use instances in workflow
    tokyo >> paris >> london
    wf.execute()
```

**å‡ºåŠ›:**
```
Weather for Tokyo
Weather for Paris
Weather for London
```

### è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ID

ã™ã¹ã¦ã« `task_id` ã‚’ä»˜ã‘ãŸããªã„å ´åˆã¯çœç•¥ã§ãã¾ã™:

```python
@task
def process(value: int) -> int:
    return value * 2

# Auto-generated IDs: process_{random_uuid}
task1 = process(value=10)  # task_id: process_a3f2b9c1
task2 = process(value=20)  # task_id: process_b7e8f4d2
task3 = process(value=30)  # task_id: process_c5d9e6f7

with workflow("auto_ids") as wf:
    task1 >> task2 >> task3
    wf.execute()
```

**âš ï¸ æ³¨æ„: ã‚¿ã‚¹ã‚¯IDã®ä¸€æ„æ€§ã‚’ç¢ºä¿**

è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã™ã‚‹å ´åˆã€ã‚¿ã‚¹ã‚¯IDã¯å¿…ãšä¸€æ„ã«ã—ã¾ã™:

```python
# âœ… Good: Unique task_ids
tokyo = fetch_weather(task_id="tokyo", city="Tokyo")
paris = fetch_weather(task_id="paris", city="Paris")
london = fetch_weather(task_id="london", city="London")

# âŒ Bad: Duplicate task_ids cause conflicts
task1 = fetch_weather(task_id="fetch", city="Tokyo")
task2 = fetch_weather(task_id="fetch", city="Paris")  # ERROR: "fetch" already exists!

# âœ… Good: Auto-generated IDs are always unique
task1 = fetch_weather(city="Tokyo")   # Auto: fetch_weather_a3f2b9c1
task2 = fetch_weather(city="Paris")   # Auto: fetch_weather_b7e8f4d2
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†åˆ©ç”¨
- `task_id` ã‚’ä»˜ã‘ã‚‹å ´åˆã¯ä¸€æ„æ€§ãŒå¿…é ˆ
- `task_id` ã‚’çœç•¥ã™ã‚Œã°è‡ªå‹•ã§ä¸€æ„ãªIDãŒç”Ÿæˆã•ã‚Œã‚‹
- å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹

---

## ãƒ¬ãƒ™ãƒ«6: ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

### ãƒãƒ£ãƒ³ãƒãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

Graflowã¯ãƒ­ãƒ¼ã‚«ãƒ«/åˆ†æ•£ã®åˆ‡ã‚Šæ›¿ãˆã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«è¡Œãˆã‚‹2ç¨®é¡ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æä¾›ã—ã¾ã™:

**1. MemoryChannel (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)** - ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨:
- âœ… é«˜é€Ÿ: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã§ä½é…å»¶
- âœ… ã‚·ãƒ³ãƒ—ãƒ«: ã‚¤ãƒ³ãƒ•ãƒ©ä¸è¦
- âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆäº’æ›: è‡ªå‹•ä¿å­˜
- âš ï¸ åˆ¶ç´„: å˜ä¸€ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿

**2. RedisChannel** - åˆ†æ•£å®Ÿè¡Œç”¨:
- âœ… åˆ†æ•£: è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼/ãƒã‚·ãƒ³ã§çŠ¶æ…‹å…±æœ‰
- âœ… æ°¸ç¶š: Redisæ°¸ç¶šåŒ–ã§è€éšœå®³æ€§
- âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«: å¤šæ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã‚‚ä¸€è²«æ€§
- âš ï¸ å¿…è¦: Redisã‚µãƒ¼ãƒãƒ¼

**ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ:**

```python
# Local execution (default) - uses MemoryChannel
with workflow("local") as wf:
    task_a >> task_b
    wf.execute()

# Distributed execution - uses RedisChannel
from graflow.channels.factory import ChannelFactory, ChannelBackend

channel = ChannelFactory.create_channel(
    backend=ChannelBackend.REDIS,
    redis_client=redis_client
)

with workflow("distributed") as wf:
    task_a >> task_b
    wf.execute()
```

### ãƒãƒ£ãƒ³ãƒãƒ«ã®ä½¿ã„æ–¹

#### åŸºæœ¬ãƒãƒ£ãƒ³ãƒãƒ«: `ctx.get_channel()`

å˜ç´”ãªã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ä¿å­˜ã«ä½¿ã„ã¾ã™:

```python
@task(inject_context=True)
def producer(ctx: TaskExecutionContext):
    """Write data to channel."""
    channel = ctx.get_channel()

    # Store simple values
    channel.set("user_id", "user_123")
    channel.set("score", 95.5)
    channel.set("active", True)

    # Store complex objects
    channel.set("user_profile", {
        "name": "Alice",
        "email": "alice@example.com",
        "age": 30
    })

@task(inject_context=True)
def consumer(ctx: TaskExecutionContext):
    """Read data from channel."""
    channel = ctx.get_channel()

    # Retrieve values
    user_id = channel.get("user_id")        # "user_123"
    score = channel.get("score")            # 95.5
    active = channel.get("active")          # True
    profile = channel.get("user_profile")   # dict

    # With default value
    setting = channel.get("setting", default="default_value")
```

**ãƒãƒ£ãƒ³ãƒãƒ«ãƒ¡ã‚½ãƒƒãƒ‰:**

| ãƒ¡ã‚½ãƒƒãƒ‰ | èª¬æ˜ | ä¾‹ |
|--------|-------------|---------|
| `set(key, value)` | å€¤ã‚’ä¿å­˜ | `channel.set("count", 42)` |
| `set(key, value, ttl)` | æœ‰åŠ¹æœŸé™ä»˜ãã§ä¿å­˜ (ç§’) | `channel.set("temp", 100, ttl=300)` |
| `get(key)` | å€¤ã‚’å–å¾— | `value = channel.get("count")` |
| `get(key, default)` | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä»˜ãã§å–å¾— | `value = channel.get("count", default=0)` |
| `append(key, value)` | ãƒªã‚¹ãƒˆæœ«å°¾ã«è¿½åŠ  | `channel.append("logs", "entry")` |
| `append(key, value, ttl)` | æœ‰åŠ¹æœŸé™ä»˜ãã§æœ«å°¾è¿½åŠ  | `channel.append("logs", "entry", ttl=60)` |
| `prepend(key, value)` | ãƒªã‚¹ãƒˆå…ˆé ­ã«è¿½åŠ  | `channel.prepend("queue", "item")` |
| `delete(key)` | ã‚­ãƒ¼ã‚’å‰Šé™¤ | `channel.delete("count")` |
| `exists(key)` | å­˜åœ¨ãƒã‚§ãƒƒã‚¯ | `if channel.exists("count"):` |

**ãƒªã‚¹ãƒˆæ“ä½œ: append() ã¨ prepend()**

è¤‡æ•°å€¤ã®åé›†ã«ä¾¿åˆ©ã§ã™:

```python
@task(inject_context=True)
def collect_logs(ctx: TaskExecutionContext):
    channel = ctx.get_channel()

    # Append to end of list (FIFO queue)
    channel.append("logs", "Log entry 1")
    channel.append("logs", "Log entry 2")
    channel.append("logs", "Log entry 3")

    logs = channel.get("logs")
    print(logs)  # ["Log entry 1", "Log entry 2", "Log entry 3"]

@task(inject_context=True)
def use_stack(ctx: TaskExecutionContext):
    channel = ctx.get_channel()

    # Prepend to beginning of list (LIFO stack)
    channel.prepend("stack", "First")
    channel.prepend("stack", "Second")
    channel.prepend("stack", "Third")

    stack = channel.get("stack")
    print(stack)  # ["Third", "Second", "First"]
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- `append()`: ãƒ­ã‚°ã®è“„ç©ã€ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ã®çµæœåé›†ã€FIFOã‚­ãƒ¥ãƒ¼
- `prepend()`: LIFOã‚¹ã‚¿ãƒƒã‚¯ã€å„ªå…ˆåº¦é«˜ã„ã‚¢ã‚¤ãƒ†ãƒ ã€é€†é †åé›†

**Time-to-Live (TTL): è‡ªå‹•æœ‰åŠ¹æœŸé™**

TTLã‚’ä½¿ã£ã¦ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•çš„ã«å‰Šé™¤ã§ãã¾ã™:

```python
@task(inject_context=True)
def cache_data(ctx: TaskExecutionContext):
    channel = ctx.get_channel()

    # Cache for 5 minutes (300 seconds)
    channel.set("api_response", {"data": "..."}, ttl=300)

    # Temporary flag expires in 60 seconds
    channel.set("processing", True, ttl=60)

    # Collect logs that expire after 10 minutes
    channel.append("recent_logs", "Error occurred", ttl=600)

@task(inject_context=True)
def check_cache(ctx: TaskExecutionContext):
    channel = ctx.get_channel()

    # After TTL expires, key is automatically removed
    data = channel.get("api_response", default="expired")
    if data == "expired":
        print("Cache expired, refetching...")
```

**TTLã®æŒ™å‹•:**
- TTLã¯**ç§’**å˜ä½
- TTLçµŒéå¾Œã«ã‚­ãƒ¼ã¯è‡ªå‹•å‰Šé™¤
- æœŸé™åˆ‡ã‚Œã‚­ãƒ¼ã« `get()` ã™ã‚‹ã¨ `None` (ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤)
- `set()` ã¨ `append()`/`prepend()` ã¯TTLå¯¾å¿œ
- ä¸€æ™‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹

**ä¾‹: TTLä»˜ãã§ä¸¦åˆ—ã‚¿ã‚¹ã‚¯çµæœã‚’åé›†**

```python
@task(inject_context=True)
def fetch_data(ctx: TaskExecutionContext, source: str):
    channel = ctx.get_channel()
    data = f"Data from {source}"

    # Collect results with 1-hour expiration
    channel.append("fetch_results", data, ttl=3600)

    return data

with workflow("collect_results") as wf:
    fetch_a = fetch_data(task_id="fetch_a", source="api")
    fetch_b = fetch_data(task_id="fetch_b", source="db")
    fetch_c = fetch_data(task_id="fetch_c", source="cache")

    parallel(fetch_a, fetch_b, fetch_c)

    wf.execute()
```

#### å‹å®‰å…¨ãªãƒãƒ£ãƒ³ãƒãƒ«: `ctx.get_typed_channel()`

å‹ä»˜ããƒãƒ£ãƒ³ãƒãƒ«ã§å‹ãƒã‚§ãƒƒã‚¯ã¨IDEè£œå®Œã‚’æ´»ç”¨ã§ãã¾ã™:

```python
from typing import TypedDict

# Define schema
class UserProfile(TypedDict):
    user_id: str
    name: str
    email: str
    age: int
    premium: bool

@task(inject_context=True)
def collect_user_data(ctx: TaskExecutionContext):
    """Store user data with type safety."""

    # Get typed channel
    typed_channel = ctx.get_typed_channel(UserProfile)

    # IDE autocompletes fields!
    user_profile: UserProfile = {
        "user_id": "user_123",
        "name": "Alice",
        "email": "alice@example.com",
        "age": 30,
        "premium": True
    }

    # Type-checked storage
    typed_channel.set("current_user", user_profile)

@task(inject_context=True)
def process_user_data(ctx: TaskExecutionContext):
    """Retrieve user data with type safety."""

    # Get typed channel with same schema
    typed_channel = ctx.get_typed_channel(UserProfile)

    # Retrieve with type hints
    user: UserProfile = typed_channel.get("current_user")

    # IDE knows the structure!
    print(user["name"])    # IDE autocompletes "name"
    print(user["email"])   # IDE autocompletes "email"
```

**å‹ä»˜ããƒãƒ£ãƒ³ãƒãƒ«ã®åˆ©ç‚¹:**

- âœ… **IDEè£œå®Œ**: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã¨å‹ãŒå€™è£œè¡¨ç¤º
- âœ… **å‹ãƒã‚§ãƒƒã‚¯**: mypy/pyrightãŒå‹ãƒŸã‚¹ã‚’æ¤œå‡º
- âœ… **è‡ªå·±æ–‡æ›¸åŒ–**: TypedDictãŒAPIå¥‘ç´„ã«ãªã‚‹
- âœ… **ãƒªãƒ•ã‚¡ã‚¯ã‚¿å®‰å…¨**: IDEã§å®‰å…¨ã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åå¤‰æ›´
- âœ… **ãƒãƒ¼ãƒ é–‹ç™º**: å…±æœ‰ã‚¹ã‚­ãƒ¼ãƒã§ãƒŸã‚¹é˜²æ­¢

**ä½¿ã„åˆ†ã‘ã®ç›®å®‰:**

| ç”¨é€” | ãƒ¡ã‚½ãƒƒãƒ‰ | ç†ç”± |
|----------|--------|-----|
| ã‚·ãƒ³ãƒ—ãƒ«ãªå€¤ (æ–‡å­—åˆ—/æ•°å€¤) | `get_channel()` | ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå°‘ãªã„ |
| ãã®å ´ã—ã®ãã®ãƒ‡ãƒ¼ã‚¿äº¤æ› | `get_channel()` | ã‚¹ã‚­ãƒ¼ãƒä¸è¦ |
| æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ | `get_typed_channel()` | å‹å®‰å…¨ |
| ãƒãƒ¼ãƒ é–‹ç™º | `get_typed_channel()` | å…±æœ‰ã‚¹ã‚­ãƒ¼ãƒ |
| å¤§è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | `get_typed_channel()` | ä¿å®ˆæ€§å‘ä¸Š |

**ä¾‹: ä½µç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
@task(inject_context=True)
def process_order(ctx: TaskExecutionContext):
    # Use typed channel for structured data
    order_channel = ctx.get_typed_channel(OrderData)
    order = order_channel.get("current_order")

    # Use basic channel for simple flags
    basic_channel = ctx.get_channel()
    basic_channel.set("processing_started", True)
    basic_channel.set("timestamp", "2024-01-01T12:00:00")
```

### ä¾å­˜æ€§æ³¨å…¥

Graflowã¯è‡ªå‹•ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹3ç¨®é¡ã®æ³¨å…¥ã‚’æä¾›ã—ã¾ã™ã€‚

#### 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥: `inject_context=True`

å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ³¨å…¥ã—ã€ãƒãƒ£ãƒ³ãƒãƒ«ã€çµæœã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™:

```python
@task(inject_context=True)
def my_task(ctx: TaskExecutionContext, value: int):
    # Access channel
    channel = ctx.get_channel()
    channel.set("result", value * 2)

    # Access session info
    print(f"Session: {ctx.session_id}")

    # Access other task results
    previous = ctx.get_result("previous_task")

    return value * 2
```

**ä½¿ã„ã©ã“ã‚:**
- ãƒãƒ£ãƒ³ãƒãƒ«çµŒç”±ã®ã‚¿ã‚¹ã‚¯é–“é€šä¿¡
- ä»–ã‚¿ã‚¹ã‚¯ã®çµæœå–å¾—
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ (next_task, next_iteration, terminate_workflow)

#### 2. LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ³¨å…¥: `inject_llm_client=True`

è»½é‡ãªLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ³¨å…¥ã—ã€ç›´æ¥APIã‚’å‘¼ã³å‡ºã—ã¾ã™:

```python
from graflow.llm.client import LLMClient

@task(inject_llm_client=True)
def analyze_text(llm: LLMClient, text: str) -> str:
    # Direct LLM API call
    response = llm.completion_text(
        messages=[{"role": "user", "content": f"Analyze: {text}"}],
        model="gpt-4o-mini"
    )
    return response
```

**ä½¿ã„ã©ã“ã‚:**
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸è¦ã®ã‚·ãƒ³ãƒ—ãƒ«ãªLLMå‘¼ã³å‡ºã—
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ (ã‚¿ã‚¹ã‚¯ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰ãˆã‚‹)
- ã‚³ã‚¹ãƒˆæœ€é©åŒ– (ç°¡å˜ãªå‡¦ç†ã¯å®‰ä¾¡ãƒ¢ãƒ‡ãƒ«)

**å¯¾å¿œ:** OpenAI ChatGPTã€Anthropic Claudeã€Google Geminiã€AWS Bedrock ãªã© (LiteLLMçµŒç”±)

#### 3. LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ³¨å…¥: `inject_llm_agent="agent_name"`

ReActãƒ«ãƒ¼ãƒ—ã¨ãƒ„ãƒ¼ãƒ«ã‚’å‚™ãˆãŸãƒ•ãƒ«æ©Ÿèƒ½ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (SuperAgent) ã‚’æ³¨å…¥ã—ã¾ã™:

```python
from graflow.llm.agents.base import LLMAgent

# First, register the agent in workflow
context.register_llm_agent("supervisor", my_agent)

# Then inject into task
@task(inject_llm_agent="supervisor")
def supervise_task(agent: LLMAgent, query: str) -> str:
    # Agent handles ReAct loop, tool calls internally
    result = agent.run(query)
    return result["output"]
```

**ä½¿ã„ã©ã“ã‚:**
- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’ä¼´ã†è¤‡é›‘ãªæ¨è«–
- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±
- è‡ªå¾‹çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯

**äº’æ›:** Google ADKã€PydanticAIã€ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

#### æ³¨å…¥ã®ã¾ã¨ã‚

| æ³¨å…¥ã‚¿ã‚¤ãƒ— | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ç”¨é€” |
|----------------|-----------|----------|
| `inject_context=True` | `ctx: TaskExecutionContext` | ãƒãƒ£ãƒ³ãƒãƒ«ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã€çµæœå–å¾— |
| `inject_llm_client=True` | `llm: LLMClient` | ã‚·ãƒ³ãƒ—ãƒ«ãªLLM APIå‘¼ã³å‡ºã— |
| `inject_llm_agent="name"` | `agent: LLMAgent` | ãƒ„ãƒ¼ãƒ«ä»˜ãã®è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç† |

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- æ³¨å…¥ã¯ã‚¿ã‚¹ã‚¯å®Ÿè¡Œæ™‚ã«è‡ªå‹•ã§è¡Œã‚ã‚Œã‚‹
- å…ˆé ­å¼•æ•°ãŒæ³¨å…¥ã•ã‚ŒãŸä¾å­˜ã‚’å—ã‘å–ã‚‹
- `inject_context=True, inject_llm_client=True` ã®ä½µç”¨ã‚‚å¯èƒ½
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯äº‹å‰ç™»éŒ²ãŒå¿…è¦: `context.register_llm_agent(name, agent)`

#### ä»£æ›¿æ¡ˆ: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµŒç”±ã§LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹

`inject_context=True` ã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµŒç”±ã§LLMã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™:

```python
@task(inject_context=True)
def task_with_llm(ctx: TaskExecutionContext, query: str):
    # Access LLM client via context
    response = ctx.llm_client.completion_text(
        messages=[{"role": "user", "content": query}],
        model="gpt-4o-mini"
    )

    # Access LLM agent via context
    agent = ctx.get_llm_agent("supervisor")
    result = agent.run(query)

    return {"llm": response, "agent": result}
```

**ä½¿ã„åˆ†ã‘:**
- ç›´æ¥æ³¨å…¥ (`inject_llm_client=True`): LLMã®ã¿ä½¿ã†å ´åˆã«ã‚·ãƒ³ãƒ—ãƒ«
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµŒç”± (`ctx.llm_client`): ãƒãƒ£ãƒ³ãƒãƒ«/åˆ¶å¾¡ã‚‚å¿…è¦ãªå ´åˆ

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†

Graflowã¯LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ»ãƒ©ãƒ™ãƒ«ç®¡ç†ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚

#### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®è¨­å®š

`PromptManagerFactory` ã‚’ä½¿ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½œæˆã—ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«æ¸¡ã—ã¾ã™:

```python
from pathlib import Path
from graflow.core.workflow import workflow
from graflow.prompts.factory import PromptManagerFactory

# YAMLãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ (ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«)
prompts_dir = Path(__file__).parent / "prompts"
pm = PromptManagerFactory.create("yaml", prompts_dir=str(prompts_dir))

# ã¾ãŸã¯ Langfuseãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ (ã‚¯ãƒ©ã‚¦ãƒ‰)
pm = PromptManagerFactory.create(
    "langfuse",
    fetch_timeout_seconds=10,  # 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    max_retries=2,             # å¤±æ•—æ™‚ã¯æœ€å¤§2å›ãƒªãƒˆãƒ©ã‚¤
)

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ¸¡ã™
with workflow("my_workflow", prompt_manager=pm) as ctx:
    # ã‚¿ã‚¹ã‚¯ã¯ context.prompt_manager ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
    ...
```

**åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰:**

| ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ | ç”¨é€” | è¨­å®š |
|---------|----------|---------------|
| `"yaml"` | ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ | `prompts_dir="./prompts"` |
| `"langfuse"` | ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã€ãƒãƒ¼ãƒ å”æ¥­ã€A/Bãƒ†ã‚¹ãƒˆ | `fetch_timeout_seconds`, `max_retries` |

**Langfuseã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—** (`pip install graflow[tracing]` ãŒå¿…è¦):
```bash
export LANGFUSE_PUBLIC_KEY=pk-lf-...
export LANGFUSE_SECRET_KEY=sk-lf-...
export LANGFUSE_HOST=https://cloud.langfuse.com  # ã¾ãŸã¯ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆURL
```

#### ã‚¿ã‚¹ã‚¯å†…ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹

`context.prompt_manager` ã‚’ä½¿ã£ã¦ã‚¿ã‚¹ã‚¯å†…ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™:

```python
@task(inject_context=True)
def greet(ctx: TaskExecutionContext) -> str:
    pm = ctx.prompt_manager

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã—ã€å¤‰æ•°ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    prompt = pm.get_text_prompt("greeting")
    return prompt.render(name="Alice", product="Graflow")
    # å‡ºåŠ›: "Hello Alice, welcome to Graflow!"
```

#### ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ vs ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

**ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ** - å˜ä¸€æ–‡å­—åˆ—ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:

```python
@task(inject_context=True)
def generate_greeting(ctx: TaskExecutionContext) -> str:
    pm = ctx.prompt_manager

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    prompt = pm.get_text_prompt("greeting")

    # render()ã¯æ–‡å­—åˆ—ã‚’è¿”ã™
    message: str = prompt.render(name="Alice")
    return message
```

**ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ** - LLM APIç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ:

```python
@task(inject_context=True)
def generate_conversation(ctx: TaskExecutionContext) -> list:
    pm = ctx.prompt_manager

    # ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    prompt = pm.get_chat_prompt("assistant")

    # render()ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¾æ›¸ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
    messages: list[dict] = prompt.render(domain="Python", task="debugging")
    # [
    #   {"role": "system", "content": "You are an expert in Python."},
    #   {"role": "user", "content": "Help me with debugging."}
    # ]
    return messages
```

#### ãƒ©ãƒ™ãƒ«ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã‚‹ã‚¢ã‚¯ã‚»ã‚¹

ç‰¹å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹:

```python
# ãƒ©ãƒ™ãƒ«æŒ‡å®š (æœ¬ç•ª/ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã«æ¨å¥¨)
prompt = pm.get_text_prompt("greeting", label="production")
prompt = pm.get_text_prompt("greeting", label="staging")

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·æŒ‡å®š
prompt = pm.get_text_prompt("greeting", version=1)
prompt = pm.get_text_prompt("greeting", version=2)
```

#### YAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼

YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜:

```yaml
# prompts/greeting.yaml
greeting:
  type: text
  labels:
    production:
      content: "Hello {{name}}, welcome to {{product}}!"
      version: 1
      metadata:
        author: "team@example.com"
    staging:
      content: "Hi {{name}}! Testing {{product}}."
      version: 2

# ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹
assistant:
  type: chat
  labels:
    production:
      content:
        - role: system
          content: "You are a helpful assistant specializing in {{domain}}."
        - role: user
          content: "Help me with {{task}}."
```

**ä¸»ãªæ©Ÿèƒ½:**
- `{{variable}}` ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ (Jinja2æ§‹æ–‡)
- ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚»ã‚¹ (`production`, `staging` ãªã©)
- ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã®è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰
- ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¯¾å¿œ (ä¾‹: `customer/welcome`)

#### å®Œå…¨ãªä¾‹

```python
from pathlib import Path
from graflow.core.workflow import workflow
from graflow.core.decorators import task
from graflow.core.context import TaskExecutionContext
from graflow.prompts.factory import PromptManagerFactory

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½œæˆ
prompts_dir = Path(__file__).parent / "prompts"
pm = PromptManagerFactory.create("yaml", prompts_dir=str(prompts_dir))

with workflow("customer_onboarding", prompt_manager=pm) as ctx:

    @task(inject_context=True)
    def setup(context: TaskExecutionContext):
        channel = context.get_channel()
        channel.set("customer_name", "Alice")
        channel.set("product_name", "Graflow")

    @task(inject_context=True)
    def greet_customer(context: TaskExecutionContext) -> str:
        pm = context.prompt_manager
        channel = context.get_channel()

        name = channel.get("customer_name")
        product = channel.get("product_name")

        # æœ¬ç•ªç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã—ã¦ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        prompt = pm.get_text_prompt("greeting", label="production")
        return prompt.render(name=name, product=product)

    @task(inject_context=True)
    def generate_assistant(context: TaskExecutionContext) -> list:
        pm = context.prompt_manager

        # LLM APIç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        prompt = pm.get_chat_prompt("assistant", label="production")
        messages = prompt.render(domain="Python", task="onboarding")

        # LLM APIã¸é€ä¿¡å¯èƒ½
        return messages

    setup >> greet_customer >> generate_assistant
    ctx.execute("setup")
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `PromptManagerFactory.create()` ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½œæˆ
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«æ¸¡ã™: `workflow("name", prompt_manager=pm)`
- ã‚¿ã‚¹ã‚¯å†…ã§ã¯ `context.prompt_manager` ã§ã‚¢ã‚¯ã‚»ã‚¹
- æ–‡å­—åˆ—ã«ã¯ `get_text_prompt()`ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«ã¯ `get_chat_prompt()`
- ç’°å¢ƒåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ãƒ©ãƒ™ãƒ« (`production`, `staging`) ã‚’ä½¿ç”¨
- å®Œå…¨ãªä¾‹ã¯ `examples/14_prompt_management/` ã‚’å‚ç…§

### Human-in-the-Loop: `ctx.request_feedback()`

`ctx.request_feedback()` ã§äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«çµ„ã¿è¾¼ã¿ã¾ã™:

```python
@task(inject_context=True)
def request_approval(ctx: TaskExecutionContext, deployment_plan: dict) -> bool:
    """Request human approval before deployment."""

    response = ctx.request_feedback(
        feedback_type="approval",
        prompt="Approve deployment to production?",
        timeout=300,  # Wait 5 minutes
        notification_config={
            "type": "slack",
            "webhook_url": "https://hooks.slack.com/services/XXX",
            "message": "Deployment approval needed!"
        }
    )

    if not response.approved:
        ctx.cancel_workflow("Deployment rejected by user")

    return response.approved
```

**ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç¨®åˆ¥:**

1. **æ‰¿èª** - Yes/No åˆ¤æ–­
   ```python
   response = ctx.request_feedback(
       feedback_type="approval",
       prompt="Approve this action?"
   )
   # response.approved: bool
   ```

2. **ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›** - è‡ªç”±å…¥åŠ›
   ```python
   response = ctx.request_feedback(
       feedback_type="text",
       prompt="Enter configuration value:"
   )
   # response.text: str
   ```

3. **é¸æŠ** - 1ã¤é¸ã¶
   ```python
   response = ctx.request_feedback(
       feedback_type="selection",
       prompt="Choose deployment environment:",
       options=["staging", "production"]
   )
   # response.selected: str
   ```

4. **è¤‡æ•°é¸æŠ** - è¤‡æ•°é¸ã¶
   ```python
   response = ctx.request_feedback(
       feedback_type="multi_selection",
       prompt="Select features to enable:",
       options=["feature_a", "feature_b", "feature_c"]
   )
   # response.selected: list[str]
   ```

**ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æŒ™å‹•:**

ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã™ã‚‹ã¨ã€Graflowã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã™:

```python
response = ctx.request_feedback(
    feedback_type="approval",
    prompt="Approve deployment?",
    timeout=300  # 5 minutes
)

# If no response within 5 minutes:
# 1. Checkpoint is automatically created
# 2. Workflow pauses
# 3. User can provide feedback later via API
# 4. Workflow resumes from checkpoint when feedback is received
```

**ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:**
- ãƒ‡ãƒ—ãƒ­ã‚¤æ‰¿èª
- ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€å®¶ã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
- ã‚¨ãƒ©ãƒ¼å›å¾©æ™‚ã®æ„æ€æ±ºå®š

### Request Feedbackã®å†ªç­‰æ€§

**HITLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯é‡è¦**: `ctx.request_feedback()` ã‚’ä½¿ã†ã‚¿ã‚¹ã‚¯ã¯å†ªç­‰ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚

**ãªãœå†ªç­‰æ€§ãŒé‡è¦ã‹:**

ã‚¿ã‚¹ã‚¯ãŒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¾…ã¡ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹ã¨:
1. ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè‡ªå‹•ä½œæˆã•ã‚Œã‚‹
2. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä¸€æ™‚åœæ­¢ã™ã‚‹
3. å¾Œã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹
4. **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã—ã€ã‚¿ã‚¹ã‚¯ãŒå†å®Ÿè¡Œã•ã‚Œã‚‹**

ã¤ã¾ã‚ŠåŒã˜ã‚¿ã‚¹ã‚¯ãŒè¤‡æ•°å›å®Ÿè¡Œã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å†å®Ÿè¡Œã—ã¦ã‚‚å®‰å…¨ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

```python
# âš ï¸ NOT Idempotent - Dangerous with request_feedback
@task(inject_context=True)
def deploy_with_approval(ctx: TaskExecutionContext):
    # Deploy FIRST (wrong order!)
    deployment_id = api.deploy_to_production()

    # Then ask for approval
    response = ctx.request_feedback(
        feedback_type="approval",
        prompt="Approve deployment?"
    )

    # If timeout occurs and task resumes, deploy happens AGAIN!
    # This creates duplicate deployments!
```

```python
# âœ… Idempotent - Safe with request_feedback
@task(inject_context=True)
def deploy_with_approval(ctx: TaskExecutionContext, deployment_plan: dict):
    channel = ctx.get_channel()

    # Check if already deployed
    if not channel.get("deployment_approved"):
        # Ask for approval FIRST
        response = ctx.request_feedback(
            feedback_type="approval",
            prompt="Approve deployment?",
            timeout=300
        )

        if not response.approved:
            ctx.cancel_workflow("Deployment rejected")

        # Mark as approved
        channel.set("deployment_approved", True)

    # Check if already deployed
    if not channel.get("deployment_completed"):
        # Deploy only once
        deployment_id = api.deploy_to_production(deployment_plan)
        channel.set("deployment_completed", True)
        channel.set("deployment_id", deployment_id)

    return channel.get("deployment_id")
```

**ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:**

1. **å‰¯ä½œç”¨ã®å‰ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¦æ±‚ã™ã‚‹**
2. **ãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ•ãƒ©ã‚°ã§å®Œäº†çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹**
3. **ãƒ•ãƒ©ã‚°ç¢ºèªå¾Œã«å‡¦ç†ã—ã¦é‡è¤‡ã‚’é˜²ã**
4. **å¤–éƒ¨APIã«ã¯å†ªç­‰æ€§ã‚­ãƒ¼ã‚’ä½¿ã†**

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:** `ctx.request_feedback()` ã‚’ä½¿ã†ã‚¿ã‚¹ã‚¯ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå†é–‹ã«å‚™ãˆã¦å¸¸ã«å†ªç­‰ã«ã—ã¾ã—ã‚‡ã†ã€‚

### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å„ªå…ˆé †ä½

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æ±ºã®å„ªå…ˆé †ã¯æ¬¡ã®é€šã‚Šã§ã™: **æ³¨å…¥ > ãƒã‚¤ãƒ³ãƒ‰ > ãƒãƒ£ãƒ³ãƒãƒ«**

```python
@task
def calculate(value: int, multiplier: int) -> int:
    return value * multiplier

# Bind value=10, multiplier from channel
task = calculate(task_id="calc", value=10)

wf.execute(initial_channel={"value": 100, "multiplier": 5})
# Result: 10 Ã— 5 = 50 (bound value beats channel value)
```

---

## ãƒ¬ãƒ™ãƒ«7: å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³

### ã‚¿ã‚¹ã‚¯çµæœã®ç†è§£

ã‚¿ã‚¹ã‚¯ãŒå€¤ã‚’è¿”ã™ã¨ã€Graflowã¯ã‚¿ã‚¹ã‚¯IDã‚’ä½¿ã£ã¦ãƒãƒ£ãƒ³ãƒãƒ«ã«ä¿å­˜ã—ã¾ã™:

```python
# Auto-generated task_id (function name)
@task
def calculate():
    return 42

# Stored as: channel.set("calculate.__result__", 42)
# Access: ctx.get_result("calculate") â†’ 42

# Custom task_id
task1 = calculate(task_id="calc1")
task2 = calculate(task_id="calc2")

# Stored as: channel.set("calc1.__result__", 42)
#            channel.set("calc2.__result__", 42)
# Access: ctx.get_result("calc1"), ctx.get_result("calc2")
```

**çµæœã®ä¿å­˜å½¢å¼:** `{task_id}.__result__`

```python
# When a task completes:
channel.set(f"{task_id}.__result__", return_value)

# When you call get_result():
def get_result(task_id: str, default=None):
    return channel.get(f"{task_id}.__result__", default)
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³1: æœ€çµ‚çµæœã‚’å–å¾—

```python
with workflow("simple") as wf:
    @task
    def compute():
        return 42

    result = wf.execute()
    print(result)  # 42 (last task's return value)
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³2: å…¨çµæœã‚’å–å¾—

å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¨ã‚¿ã‚¹ã‚¯ã®çµæœã‚’å–å¾—ã—ã¾ã™:

```python
with workflow("all_results") as wf:
    @task
    def task_a():
        return "A"

    @task
    def task_b():
        return "B"

    task_a >> task_b

    # Get execution context to access all results
    _, ctx = wf.execute(ret_context=True)

    # Access individual task results
    print(ctx.get_result("task_a"))  # Output: A
    print(ctx.get_result("task_b"))  # Output: B
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `ret_context=True` ã¯ `(final_result, execution_context)` ã‚’è¿”ã™
- `ctx.get_result(task_id)` ã§ä»»æ„ã®çµæœã‚’å–å¾—ã§ãã‚‹
- ã‚¿ã‚¹ã‚¯ãŒå€¤ã‚’è¿”ã™ã¨è‡ªå‹•ã§ä¿å­˜ã•ã‚Œã‚‹

### ãƒ‘ã‚¿ãƒ¼ãƒ³3: ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰é–‹å§‹

**è‡ªå‹•æ¤œå‡º (å¼•æ•°ãªã—):**

`wf.execute()` ã«å¼•æ•°ã‚’æ¸¡ã•ãªã„ã¨ã€é–‹å§‹ãƒãƒ¼ãƒ‰ãŒè‡ªå‹•æ¤œå‡ºã•ã‚Œã¾ã™:

```python
with workflow("auto_start") as wf:
    @task
    def step1():
        print("Step 1")

    @task
    def step2():
        print("Step 2")

    step1 >> step2

    # Auto-detects step1 (node with no predecessors)
    wf.execute()
```

**è‡ªå‹•æ¤œå‡ºã®ä»•çµ„ã¿:**
1. **å…¥æ¬¡æ•°ãŒ0ã®ãƒãƒ¼ãƒ‰** (å…ˆè¡Œã‚¿ã‚¹ã‚¯ãªã—) ã‚’æ¢ã™
2. **1ã¤ã®ã¿**ãªã‚‰ãã‚ŒãŒé–‹å§‹ãƒãƒ¼ãƒ‰
3. **0å€‹**ãªã‚‰ `GraphCompilationError` (ç©º/å¾ªç’°)
4. **è¤‡æ•°**ãªã‚‰ `GraphCompilationError` (é–‹å§‹ç‚¹ãŒæ›–æ˜§)

**ä¾‹: è¤‡æ•°ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ (ã‚¨ãƒ©ãƒ¼)**

```python
with workflow("ambiguous") as wf:
    @task
    def task_a():
        print("A")

    @task
    def task_b():
        print("B")

    @task
    def task_c():
        print("C")

    # Two separate chains - two entry points!
    task_a >> task_c
    task_b >> task_c

    # ERROR: Multiple start nodes found (task_a and task_b)
    # wf.execute()  # Raises GraphCompilationError

    # Solution: Specify start node explicitly
    wf.execute(start_node="task_a")
```

**é–‹å§‹ãƒãƒ¼ãƒ‰ã‚’æ‰‹å‹•æŒ‡å®š:**

å‰æ®µã®ã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸã„å ´åˆã¯é–‹å§‹ãƒãƒ¼ãƒ‰ã‚’æ˜ç¤ºã—ã¾ã™:

```python
with workflow("skip") as wf:
    @task
    def step1():
        print("Step 1")

    @task
    def step2():
        print("Step 2")

    @task
    def step3():
        print("Step 3")

    step1 >> step2 >> step3

    # Start from step2 (skip step1)
    wf.execute(start_node="step2")
```

**å‡ºåŠ›:**
```
Step 2
Step 3
```

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `wf.execute()` ã¯é–‹å§‹ãƒãƒ¼ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º
- é–‹å§‹ãƒãƒ¼ãƒ‰ãŒ0/è¤‡æ•°ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
- `wf.execute(start_node="task_id")` ã§é–‹å§‹ç‚¹ã‚’æŒ‡å®š
- `wf.execute(ret_context=True)` ã¯ `(result, context)` ã‚’è¿”ã™
- `ctx.get_result(task_id)` ã§çµæœå–å¾—

---

## ãƒ¬ãƒ™ãƒ«8: è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³

1ã¤ã®ã‚¿ã‚¹ã‚¯ãŒåˆ†å²ã—ã€ä¸¦åˆ—å®Ÿè¡Œå¾Œã«åˆæµã—ã¾ã™:

```python
@task(inject_context=True)
def source(ctx: TaskExecutionContext, value: int) -> int:
    ctx.get_channel().set("value", value)
    return value

@task(inject_context=True)
def double(ctx: TaskExecutionContext) -> int:
    value = ctx.get_channel().get("value")
    result = value * 2
    ctx.get_channel().set("doubled", result)
    return result

@task(inject_context=True)
def triple(ctx: TaskExecutionContext) -> int:
    value = ctx.get_channel().get("value")
    result = value * 3
    ctx.get_channel().set("tripled", result)
    return result

@task(inject_context=True)
def combine(ctx: TaskExecutionContext) -> int:
    doubled = ctx.get_channel().get("doubled")
    tripled = ctx.get_channel().get("tripled")
    return doubled + tripled

with workflow("diamond") as wf:
    src = source(task_id="src", value=5)

    # Diamond: src â†’ (double | triple) â†’ combine
    src >> (double | triple) >> combine

    result = wf.execute(start_node="src")
    print(result)  # Output: 25 (5*2 + 5*3)
```

### è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

è¤‡æ•°ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¸¦åˆ—å‡¦ç†ã™ã‚‹ä¾‹:

```python
@task
def fetch(source: str) -> dict:
    return {"source": source, "data": f"data_{source}"}

@task
def process(data: dict) -> str:
    return f"Processed {data['source']}"

with workflow("multi_pipeline") as wf:
    # Create instances
    fetch_a = fetch(task_id="fetch_a", source="api")
    fetch_b = fetch(task_id="fetch_b", source="db")
    fetch_c = fetch(task_id="fetch_c", source="file")

    # Run in parallel
    all_fetches = fetch_a | fetch_b | fetch_c

    _, ctx = wf.execute(
        start_node=all_fetches.task_id,
        ret_context=True
    )

    # Get results
    for task_id in ["fetch_a", "fetch_b", "fetch_c"]:
        print(ctx.get_result(task_id))
```

**ğŸ’¡ é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³:** ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ â†’ `|` ã§ä¸¦åˆ— â†’ å®Ÿè¡Œ

---

## ãƒ¬ãƒ™ãƒ«9: å‹•çš„ã‚¿ã‚¹ã‚¯ç”Ÿæˆ

**é«˜åº¦ãªæ©Ÿèƒ½**: å®Ÿè¡Œä¸­ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•ã‚’å¤‰æ›´ã§ãã¾ã™ã€‚

### ãªãœå®Ÿè¡Œæ™‚ã«å‹•çš„ã«ã™ã‚‹ã®ã‹?

**ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã‚°ãƒ©ãƒ•ã®å•é¡Œ:**

å¤šãã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€åˆ†å²ã‚„ãƒ«ãƒ¼ãƒ—ã‚’äº‹å‰å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

```python
# âŒ Compile-time approach (LangGraph style)
def should_retry(state):
    return "retry" if state["score"] < 0.8 else "continue"

graph.add_conditional_edges(
    "process",
    should_retry,  # All paths predefined
    {
        "retry": "retry_node",
        "continue": "finalize_node"
    }
)
app = graph.compile()  # Graph is now fixed
```

**åˆ¶é™äº‹é …:**
- ã™ã¹ã¦ã®åˆ†å²ã‚’äº‹å‰ã«å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
- å‹•çš„æ¡ä»¶ (ãƒ•ã‚¡ã‚¤ãƒ«æ•°/ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º) ã®æ‰±ã„ãŒé›£ã—ã„
- ãƒ«ãƒ¼ãƒ—å›æ•°ãŒå®šç¾©æ™‚ã«å›ºå®šã•ã‚Œã‚‹
- é©å¿œçš„ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’è¡¨ç¾ã—ã¥ã‚‰ã„

**Graflowã®è§£æ±ºç­–: å®Ÿè¡Œæ™‚ã®æŸ”è»Ÿæ€§**

Graflowã§ã¯é€šå¸¸ã®Pythonæ¡ä»¶åˆ†å²ã‚’ä½¿ã„ã€å¿…è¦ã«å¿œã˜ã¦ã‚¿ã‚¹ã‚¯ã‚’å‹•çš„ç”Ÿæˆã§ãã¾ã™ã€‚

### å®Ÿè¡Œæ™‚ã«ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹

`context.next_task()` ã‚’ä½¿ã£ã¦ã‚¿ã‚¹ã‚¯ã‚’å‹•çš„ã«è¿½åŠ ã—ãŸã‚Šã€æ—¢å­˜ã‚¿ã‚¹ã‚¯ã¸ã‚¸ãƒ£ãƒ³ãƒ—ã§ãã¾ã™:

**`goto` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**

- **`ctx.next_task(task, goto=False)`** (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ):
  - ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
  - ç¾åœ¨ã‚¿ã‚¹ã‚¯çµ‚äº†å¾Œã«é€šå¸¸ã®å¾Œç¶šã¸é€²ã‚€
  - è¿½åŠ ä½œæ¥­ã‚’è¡Œã„ã¤ã¤åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã¯å¤‰ãˆãªã„

- **`ctx.next_task(task, goto=True)`**:
  - æŒ‡å®šã‚¿ã‚¹ã‚¯ã¸å³æ™‚ã‚¸ãƒ£ãƒ³ãƒ—
  - ç¾åœ¨ã‚¿ã‚¹ã‚¯ã®å¾Œç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—
  - **æ—¢ã«ã‚°ãƒ©ãƒ•ã«å­˜åœ¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¸ã®ã‚¸ãƒ£ãƒ³ãƒ—ã«ä½¿ã†**

**ä¾‹1: æ—¢å­˜ã‚¿ã‚¹ã‚¯ã¸ã®ã‚¸ãƒ£ãƒ³ãƒ—**

`goto=True` ã‚’ä½¿ã£ã¦ã€ã™ã§ã«å®šç¾©æ¸ˆã¿ã®ã‚¿ã‚¹ã‚¯ã«ã‚¸ãƒ£ãƒ³ãƒ—ã—ã¾ã™:

```python
with workflow("error_handling") as wf:
    @task(inject_context=True)
    def risky_operation(ctx: TaskExecutionContext):
        """Process data with potential errors."""
        try:
            # Risky operation
            if random.random() < 0.3:  # 30% chance of critical error
                raise CriticalError("Critical failure!")
            print("Operation succeeded")
        except CriticalError:
            # Jump to existing emergency handler task
            emergency_task = ctx.graph.get_node("emergency_handler")
            ctx.next_task(emergency_task, goto=True)  # Skip normal successors

    @task
    def emergency_handler():
        """Handle emergency situations."""
        print("Emergency handler activated!")
        # Send alerts, rollback, etc.

    @task
    def normal_continuation():
        """This runs only if risky_operation succeeds."""
        print("Continuing normal flow")

    # Define workflow
    risky_operation >> normal_continuation

    wf.execute()
```

**å‡ºåŠ› (ã‚¨ãƒ©ãƒ¼æ™‚):**
```
Emergency handler activated!
```

**å‡ºåŠ› (æˆåŠŸæ™‚):**
```
Operation succeeded
Continuing normal flow
```

**ä¾‹2: æ¡ä»¶åˆ†å²ã§æ—¢å­˜ã‚¿ã‚¹ã‚¯ã¸**

```python
with workflow("conditional") as wf:
    @task(inject_context=True)
    def router(ctx: TaskExecutionContext, user_type: str):
        """Route to different paths based on user type."""
        if user_type == "premium":
            premium_task = ctx.graph.get_node("premium_flow")
            ctx.next_task(premium_task, goto=True)
        elif user_type == "basic":
            basic_task = ctx.graph.get_node("basic_flow")
            ctx.next_task(basic_task, goto=True)

    @task
    def premium_flow():
        print("Premium user processing")

    @task
    def basic_flow():
        print("Basic user processing")

    @task
    def default_continuation():
        print("This is skipped when goto=True")

    router >> default_continuation

    wf.execute(initial_channel={"user_type": "premium"})
```

**ä¾‹3: è¿½åŠ ä½œæ¥­ã®ã‚¨ãƒ³ã‚­ãƒ¥ãƒ¼ (goto=False)**

`goto=False` (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) ã§åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚’å¤‰ãˆãšã«ã‚¿ã‚¹ã‚¯è¿½åŠ :

```python
@task(inject_context=True)
def process(ctx: TaskExecutionContext):
    @task
    def extra_logging():
        print("Extra logging task")

    # Enqueue: Add extra_logging, then continue to normal successors
    ctx.next_task(extra_logging)  # goto=False is default

    print("Main processing")

@task
def continuation():
    print("Normal continuation")

with workflow("enqueue_demo") as wf:
    process >> continuation
    wf.execute()
```

**å‡ºåŠ›:**
```
Main processing
Extra logging task
Normal continuation
```

**ğŸ’¡ é‡è¦ãªé•ã„:**
- **`goto=False`** (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ): ã€Œã“ã®ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ã€é€šå¸¸ã©ãŠã‚Šç¶šè¡Œã€
- **`goto=True`**: ã€Œæ—¢å­˜ã‚¿ã‚¹ã‚¯ã¸ã‚¸ãƒ£ãƒ³ãƒ—ã—ã€é€šå¸¸ã®å¾Œç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—ã€
- æ—¢å­˜ã‚¿ã‚¹ã‚¯ã®å–å¾—ã¯ `ctx.graph.get_node(task_id)`

### next_iteration ã«ã‚ˆã‚‹è‡ªå·±ãƒ«ãƒ¼ãƒ—

`context.next_iteration()` ã‚’ä½¿ã£ã¦ãƒªãƒˆãƒ©ã‚¤/åæŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿç¾ã§ãã¾ã™:

```python
@task(inject_context=True)
def optimize(ctx: TaskExecutionContext):
    """Optimize until convergence."""
    channel = ctx.get_channel()
    iteration = channel.get("iteration", default=0)
    accuracy = channel.get("accuracy", default=0.5)

    # Training step
    new_accuracy = train_step(accuracy)
    print(f"Iteration {iteration}: accuracy={new_accuracy:.2f}")

    if new_accuracy >= 0.95:
        # Converged!
        print("Converged!")
        channel.set("final_accuracy", new_accuracy)
    else:
        # Continue iterating
        channel.set("iteration", iteration + 1)
        channel.set("accuracy", new_accuracy)
        ctx.next_iteration()

with workflow("optimization") as wf:
    wf.execute()
```

**å‡ºåŠ›ä¾‹:**
```
Iteration 0: accuracy=0.65
Iteration 1: accuracy=0.78
Iteration 2: accuracy=0.88
Iteration 3: accuracy=0.96
Converged!
```

**ğŸ’¡ ä¸»ãªç”¨é€”:**
- æœ€å¤§è©¦è¡Œå›æ•°ä»˜ãã®ãƒªãƒˆãƒ©ã‚¤
- MLãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
- åæŸå‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- æ®µéšçš„æ”¹å–„

### æ—©æœŸçµ‚äº†

#### æ­£å¸¸çµ‚äº†: terminate_workflow

æ­£å¸¸ã«çµ‚äº†ã—ãŸã„å ´åˆ:

```python
@task(inject_context=True)
def check_cache(ctx: TaskExecutionContext, key: str):
    """Check cache before processing."""
    cached = get_from_cache(key)

    if cached is not None:
        # Cache hit - no need to continue
        print(f"Cache hit: {cached}")
        ctx.terminate_workflow("Data found in cache")
        return cached

    # Cache miss - continue to next tasks
    print("Cache miss, proceeding...")
    return None

@task
def expensive_processing():
    """This won't run if cache hits."""
    print("Expensive processing...")
    return "processed"

with workflow("caching") as wf:
    check_cache(task_id="cache", key="my_key") >> expensive_processing
    wf.execute()
```

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚:**
```
Cache hit: cached_value
```

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚:**
```
Cache miss, proceeding...
Expensive processing...
```

#### ç•°å¸¸çµ‚äº†: cancel_workflow

ã‚¨ãƒ©ãƒ¼æ™‚ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’åœæ­¢ã—ãŸã„å ´åˆ:

```python
@task(inject_context=True)
def validate_data(ctx: TaskExecutionContext, data: dict):
    """Validate data before processing."""
    if not data.get("valid"):
        # Invalid data - cancel entire workflow
        ctx.cancel_workflow("Data validation failed")

    return data

@task
def process_data(data: dict):
    print("Processing data...")
    return data

with workflow("validation") as wf:
    validate = validate_data(task_id="validate", data={"valid": False})
    validate >> process_data

    try:
        wf.execute()
    except Exception as e:
        print(f"Workflow canceled: {e}")
```

**å‡ºåŠ›:**
```
Workflow canceled: Data validation failed
```

**é•ã„:**

| ãƒ¡ã‚½ãƒƒãƒ‰ | ã‚¿ã‚¹ã‚¯å®Œäº†? | å¾Œç¶šå®Ÿè¡Œ? | ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ? |
|--------|----------------|---------------|-------------|
| `terminate_workflow` | âœ… Yes | âŒ No | âŒ No |
| `cancel_workflow` | âŒ No | âŒ No | âœ… Yes (GraflowWorkflowCanceledError) |

**ğŸ’¡ é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `next_task(task)` ã¯ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã¦å¾Œç¶šã«é€²ã‚€
- `next_task(task, goto=True)` ã¯ã‚¸ãƒ£ãƒ³ãƒ—ã—ã¦å¾Œç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—
- `next_iteration()` ã¯è‡ªå·±ãƒ«ãƒ¼ãƒ—ã§ãƒªãƒˆãƒ©ã‚¤/åæŸ
- `terminate_workflow()` ã¯æ­£å¸¸çµ‚äº†
- `cancel_workflow()` ã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. å†åˆ©ç”¨æ€§ã®ãŸã‚ã«ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ã†

```python
# âœ… Good - Reusable task definition
@task
def fetch_data(source: str):
    return fetch(source)

api = fetch_data(task_id="api", source="api")
db = fetch_data(task_id="db", source="database")

# âŒ Avoid - Duplicated definitions
@task
def fetch_api():
    return fetch("api")

@task
def fetch_db():
    return fetch("database")
```

### 2. å‹ãƒ’ãƒ³ãƒˆã‚’å¿…ãšä½¿ã†

```python
# âœ… Good
@task
def process(value: int, multiplier: int = 2) -> int:
    return value * multiplier

# âŒ Avoid
@task
def process(value, multiplier=2):
    return value * multiplier
```

### 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ã¯å¿…è¦ãªã¨ãã ã‘

```python
# âœ… Simple computation - no context needed
@task
def add(x: int, y: int) -> int:
    return x + y

# âœ… Inter-task communication - needs context
@task(inject_context=True)
def share_data(ctx: TaskExecutionContext, value: int):
    ctx.get_channel().set("shared", value)
```

### 4. åˆ†ã‹ã‚Šã‚„ã™ã„ã‚¿ã‚¹ã‚¯IDã‚’ä½¿ã†

```python
# âœ… Good - Clear and descriptive
fetch_user_profile = fetch(task_id="fetch_user_profile")
validate_email = validate(task_id="validate_email")

# âŒ Avoid - Generic names
task1 = fetch(task_id="t1")
task2 = validate(task_id="t2")
```

### 5. ret_context ã§çµæœã‚’å–å¾—ã™ã‚‹

```python
# âœ… Good - Access all task results
_, ctx = wf.execute(ret_context=True)
result_a = ctx.get_result("task_a")
result_b = ctx.get_result("task_b")

# âš ï¸ Limited - Only final result
result = wf.execute()  # Only last task's result
```

---

## ã¾ã¨ã‚

### å­¦ç¿’ãƒ‘ã‚¹

1. **ã“ã“ã‹ã‚‰é–‹å§‹**: [ãƒ¬ãƒ™ãƒ«1](#ãƒ¬ãƒ™ãƒ«1-æœ€åˆã®ã‚¿ã‚¹ã‚¯) - æœ€åˆã®ã‚¿ã‚¹ã‚¯
2. **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰**: [ãƒ¬ãƒ™ãƒ«2](#ãƒ¬ãƒ™ãƒ«2-æœ€åˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼) - ã‚¿ã‚¹ã‚¯æ¥ç¶š
3. **åˆæˆ**: [ãƒ¬ãƒ™ãƒ«3](#ãƒ¬ãƒ™ãƒ«3-ã‚¿ã‚¹ã‚¯åˆæˆ) - ç›´åˆ—/ä¸¦åˆ—
4. **ãƒ‡ãƒ¼ã‚¿å—ã‘æ¸¡ã—**: [ãƒ¬ãƒ™ãƒ«4](#ãƒ¬ãƒ™ãƒ«4-ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å—ã‘æ¸¡ã—) - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒãƒ£ãƒ³ãƒãƒ«
5. **å†åˆ©ç”¨**: [ãƒ¬ãƒ™ãƒ«5](#ãƒ¬ãƒ™ãƒ«5-ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹) - ã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
6. **çŠ¶æ…‹å…±æœ‰**: [ãƒ¬ãƒ™ãƒ«6](#ãƒ¬ãƒ™ãƒ«6-ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ) - ãƒãƒ£ãƒ³ãƒãƒ«ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
7. **å®Ÿè¡Œåˆ¶å¾¡**: [ãƒ¬ãƒ™ãƒ«7](#ãƒ¬ãƒ™ãƒ«7-å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³) - å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
8. **è¤‡é›‘ãƒ‘ã‚¿ãƒ¼ãƒ³**: [ãƒ¬ãƒ™ãƒ«8](#ãƒ¬ãƒ™ãƒ«8-è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼) - ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰/è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
9. **é«˜åº¦ãªæ©Ÿèƒ½**: [ãƒ¬ãƒ™ãƒ«9](#ãƒ¬ãƒ™ãƒ«9-å‹•çš„ã‚¿ã‚¹ã‚¯ç”Ÿæˆ) - å‹•çš„ã‚¿ã‚¹ã‚¯

### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å„ªå…ˆé †ä½

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æ±ºã®å„ªå…ˆé †ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ (é«˜ã„ã»ã©å„ªå…ˆ):

```
Injection > Bound > Channel
   (ctx)    (task_id)  (initial_channel)
```

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**ä¾‹ã‚’ç¢ºèª:**
- `examples/01_basics/` - åŸºæœ¬ã‚¿ã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
- `examples/02_workflows/` - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆæˆ
- `examples/07_dynamic_tasks/` - å‹•çš„ã‚¿ã‚¹ã‚¯ç”Ÿæˆ

**é«˜åº¦ãªæ©Ÿèƒ½:**
- [Checkpoint & Resume](checkpoint/checkpoint_resume_design.md) - éšœå®³è€æ€§
- [HITL](hitl/hitl_design.md) - Human-in-the-loopãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- [Distributed Execution](scaling/redis_distributed_execution_redesign.md) - ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«:**
- `graflow/core/task.py` - ã‚¿ã‚¹ã‚¯å®Ÿè£…
- `graflow/core/workflow.py` - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
- `graflow/core/engine.py` - å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³

---

**Graflowãƒãƒ¼ãƒ ã‚ˆã‚Š â¤ï¸**
