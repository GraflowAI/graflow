# GPT Newspaper Environment Configuration

# Required: Tavily API Key for web search
# Get your key at: https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key_here

# Required: LLM Provider API Key
# OpenAI (recommended)
OPENAI_API_KEY=your_openai_api_key_here

# Or use other providers supported by litellm:
# ANTHROPIC_API_KEY=your_anthropic_key_here
# COHERE_API_KEY=your_cohere_key_here
# etc.

# Optional: Override default LLM model (uses Graflow's LLM integration)
# Default: gpt-4o-mini
# Supported models: any LiteLLM-compatible model
# Examples:
#   - gpt-4o-mini (fast, cheap, recommended for development)
#   - gpt-4o (powerful, expensive, better quality)
#   - claude-3-5-sonnet-20241022 (Anthropic, excellent reasoning)
#   - gemini-2.5-flash (Google, very fast)
GRAFLOW_LLM_MODEL=gpt-5-mini

# For local models (Ollama example):
# GRAFLOW_LLM_MODEL=ollama_chat/llama3.2:3b
# GRAFLOW_MODEL_PARAMS={"api_base": "http://localhost:11434"}

# Optional: Additional model parameters (JSON format)
# GRAFLOW_MODEL_PARAMS={"temperature": 0.7, "max_tokens": 2048}

# Optional: Override default layout (layout_1.html, layout_2.html, layout_3.html)
# NEWSPAPER_LAYOUT=layout_1.html

# Optional: Override max critique iterations
# MAX_CRITIQUE_ITERATIONS=5

# Optional: Override output directory
# OUTPUT_DIR=outputs

# Optional: Langfuse tracing configuration
# Enable tracing to monitor LLM calls and workflow execution in Langfuse
# Get your keys at: https://cloud.langfuse.com/
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_HOST=https://cloud.langfuse.com  # Default, or use self-hosted URL
# LANGFUSE_HOST=http://host.docker.internal:3000  # For local Docker Langfuse

