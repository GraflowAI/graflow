# Agent Workflow Visual Architecture

## Workflow Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AGENT WORKFLOW ARCHITECTURE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  topic_intake    â”‚
                        â”‚ â€¢ Setup query    â”‚
                        â”‚ â€¢ Register agentsâ”‚
                        â”‚ â€¢ Init channels  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          RESEARCH AGENT (autonomous)               â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ ğŸ¤– LLMAgent with ReAct Pattern               â”‚  â”‚
        â”‚  â”‚                                               â”‚  â”‚
        â”‚  â”‚ Tools:                                        â”‚  â”‚
        â”‚  â”‚  â€¢ web_search(query) â†’ Tavily API           â”‚  â”‚
        â”‚  â”‚  â€¢ extract_key_facts(sources, focus)        â”‚  â”‚
        â”‚  â”‚  â€¢ refine_search_query(original, findings)  â”‚  â”‚
        â”‚  â”‚                                               â”‚  â”‚
        â”‚  â”‚ Flow:                                         â”‚  â”‚
        â”‚  â”‚  1. web_search("AI developments")            â”‚  â”‚
        â”‚  â”‚  2. extract_key_facts(results, "statistics") â”‚  â”‚
        â”‚  â”‚  3. refine_search_query("AI", findings)      â”‚  â”‚
        â”‚  â”‚  4. web_search(refined_query)                â”‚  â”‚
        â”‚  â”‚  5. Compile comprehensive report             â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ {summary, sources, image}
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     curate       â”‚
                      â”‚ Simple LLM task  â”‚
                      â”‚ â€¢ Structure      â”‚
                      â”‚   research       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ {structure, sources}
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚      write       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Simple LLM task  â”‚         â”‚
                      â”‚ â€¢ Draft article  â”‚         â”‚
                      â”‚ â€¢ OR revise with â”‚         â”‚
                      â”‚   feedback       â”‚         â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                               â”‚ {article}         â”‚
                               â–¼                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
        â”‚        EDITORIAL AGENT (autonomous)      â”‚     â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚
        â”‚  â”‚ ğŸ¤– LLMAgent with ReAct Pattern     â”‚  â”‚     â”‚
        â”‚  â”‚                                     â”‚  â”‚     â”‚
        â”‚  â”‚ Tools:                              â”‚  â”‚     â”‚
        â”‚  â”‚  â€¢ check_factual_claims()          â”‚  â”‚     â”‚
        â”‚  â”‚  â€¢ assess_readability() â†’ textstat â”‚  â”‚     â”‚
        â”‚  â”‚  â€¢ verify_sources()                â”‚  â”‚     â”‚
        â”‚  â”‚  â€¢ suggest_improvements()          â”‚  â”‚     â”‚
        â”‚  â”‚                                     â”‚  â”‚     â”‚
        â”‚  â”‚ Flow:                               â”‚  â”‚     â”‚
        â”‚  â”‚  1. check_factual_claims(article)  â”‚  â”‚     â”‚
        â”‚  â”‚  2. assess_readability(content)    â”‚  â”‚     â”‚
        â”‚  â”‚  3. verify_sources(sources)        â”‚  â”‚     â”‚
        â”‚  â”‚  4. Decide: APPROVE or REVISE      â”‚  â”‚     â”‚
        â”‚  â”‚  5. If REVISE:                     â”‚  â”‚     â”‚
        â”‚  â”‚     suggest_improvements()         â”‚  â”‚     â”‚
        â”‚  â”‚     â†’ goto write_task â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚  â”‚  6. If APPROVE: continue           â”‚  â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ approved
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     design       â”‚
                      â”‚ â€¢ Create HTML    â”‚
                      â”‚ â€¢ Save file      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
  â”Œâ”€â”€â”€â”€â”€â”€â”
  â”‚ Task â”‚  = Regular task
  â””â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ğŸ¤– LLMAgent    â”‚  = Agent with tools (autonomous)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â†’  = Data flow
  â†‘â†“ = Revision loop (agent-controlled)
```

## Agent Comparison

### Research Agent vs Search Task

**Traditional Search (Simple Workflow)**
```python
@task
def search_task(query: str) -> Dict:
    # Single search call
    sources = tavily.search(query)
    return {"sources": sources}
```

**Research Agent (Agent Workflow)**
```python
@task(inject_llm_agent="researcher")
def research_task(llm_agent: LLMAgent, query: str) -> Dict:
    # Agent autonomously:
    # - Searches multiple times
    # - Extracts relevant facts
    # - Refines queries based on findings
    # - Decides when to stop
    result = llm_agent.run("Research thoroughly: " + query)
    return result["output"]
```

**Key Difference**: Agent makes autonomous decisions about tool usage

---

### Editorial Agent vs Critique Task

**Traditional Critique (Simple Workflow)**
```python
@task(inject_llm_client=True)
def critique_task(llm: LLMClient, article: Dict) -> Dict:
    # Fixed prompt, single LLM call
    messages = [{"role": "user", "content": f"Critique: {article}"}]
    critique = llm.completion_text(messages)

    # Fixed logic for revision decision
    if "issues" in critique.lower():
        context.next_task(write_task, goto=True)

    return {"critique": critique}
```

**Editorial Agent (Agent Workflow)**
```python
@task(inject_llm_agent="editor")
def editorial_task(llm_agent: LLMAgent, article: Dict) -> Dict:
    # Agent autonomously:
    # - Checks facts with tool
    # - Assesses readability with tool
    # - Verifies sources with tool
    # - Decides approve/revise based on evidence
    # - Generates specific improvement suggestions
    result = llm_agent.run(
        f"Review article. Use tools to verify quality. "
        f"Decide: APPROVE or REVISE with specific feedback."
    )

    # Agent controls the loop decision
    if result["decision"] == "revise":
        context.next_task(write_task, goto=True)

    return result
```

**Key Difference**: Agent uses tools for verification, makes evidence-based decisions

---

## Tool Call Flow Example

### Research Agent in Action

```
User Query: "Latest developments in artificial intelligence"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent Reasoning (internal to agent)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ Thought: I need to search for recent AI developments    â”‚
â”‚ Action: web_search("AI developments 2024")              â”‚
â”‚ Observation: Found 5 articles about LLMs and robotics   â”‚
â”‚                                                          â”‚
â”‚ Thought: Good start, but need more specific data        â”‚
â”‚ Action: extract_key_facts(results, "statistics")        â”‚
â”‚ Observation: Extracted market size, funding data        â”‚
â”‚                                                          â”‚
â”‚ Thought: Missing regulatory aspect                      â”‚
â”‚ Action: refine_search_query("AI", findings)             â”‚
â”‚ Observation: Suggested "AI regulation 2024"             â”‚
â”‚                                                          â”‚
â”‚ Thought: Let me search for regulations                  â”‚
â”‚ Action: web_search("AI regulation 2024")                â”‚
â”‚ Observation: Found policy updates, EU AI Act            â”‚
â”‚                                                          â”‚
â”‚ Thought: Now I have comprehensive coverage               â”‚
â”‚ Final Output: {                                          â”‚
â”‚   summary: "...",                                        â”‚
â”‚   sources: [...],                                        â”‚
â”‚   key_findings: [...]                                    â”‚
â”‚ }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Editorial Agent in Action

```
Article: "AI Market to Reach $500B by 2024"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent Reasoning (internal to agent)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ Thought: Need to verify claims systematically            â”‚
â”‚ Action: check_factual_claims(article, sources)          â”‚
â”‚ Observation: "$500B" claim not found in sources         â”‚
â”‚                                                          â”‚
â”‚ Thought: Check if writing is clear                      â”‚
â”‚ Action: assess_readability(article_text)                â”‚
â”‚ Observation: Flesch score 45 (difficult), grade 12      â”‚
â”‚                                                          â”‚
â”‚ Thought: Verify source credibility                      â”‚
â”‚ Action: verify_sources(sources)                         â”‚
â”‚ Observation: 2/5 sources from credible domains          â”‚
â”‚                                                          â”‚
â”‚ Thought: Multiple issues found, need revision            â”‚
â”‚ Decision: REVISE                                         â”‚
â”‚ Action: suggest_improvements(article, issues)           â”‚
â”‚ Observation: Generated 4 specific suggestions            â”‚
â”‚                                                          â”‚
â”‚ Final Output: {                                          â”‚
â”‚   decision: "revise",                                    â”‚
â”‚   issues: ["unverified claim", "poor readability"],     â”‚
â”‚   suggestions: "1. Verify $500B claim...\n2. ..."       â”‚
â”‚ }                                                        â”‚
â”‚                                                          â”‚
â”‚ â†’ Workflow: next_task(write_task, goto=True)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Channel State Flow

```
Channel State Progression:

topic_intake:
  channel.set("query", "AI developments")
  channel.set("iteration", 0)

research_agent:
  channel.set("research_summary", "...")
  channel.set("research_sources", [...])
  channel.set("image", "https://...")

curate:
  channel.set("curated", {structure, sources})

write (iteration 0):
  channel.set("article", {title, content, ...})
  channel.set("iteration", 0)

editorial_agent (decision: revise):
  article["editorial_feedback"] = {suggestions, issues}
  channel.set("article", article)
  channel.set("iteration", 1)
  â†’ goto write_task

write (iteration 1):
  # Read article from channel (has editorial_feedback)
  # Incorporate suggestions
  channel.set("article", revised_article)
  channel.set("iteration", 1)

editorial_agent (decision: approve):
  article["editorial_feedback"] = None
  channel.set("article", article)
  â†’ continue to design

design:
  article = channel.get("article")
  # Create HTML
```

---

## Langfuse Trace Structure

The agent workflow produces rich traces in Langfuse:

```
Trace: article_agent_article_0
â”œâ”€ Span: topic_intake
â”‚  â””â”€ duration: 50ms
â”‚
â”œâ”€ Span: research (LLMAgent)
â”‚  â”œâ”€ Span: LlmAgent.run
â”‚  â”‚  â”œâ”€ Generation: planning
â”‚  â”‚  â”œâ”€ Tool Call: web_search("AI developments")
â”‚  â”‚  â”‚  â””â”€ result: {...}
â”‚  â”‚  â”œâ”€ Generation: reasoning
â”‚  â”‚  â”œâ”€ Tool Call: extract_key_facts(sources, "statistics")
â”‚  â”‚  â”‚  â””â”€ result: {...}
â”‚  â”‚  â”œâ”€ Generation: refinement
â”‚  â”‚  â”œâ”€ Tool Call: web_search("AI regulation 2024")
â”‚  â”‚  â”‚  â””â”€ result: {...}
â”‚  â”‚  â””â”€ Generation: final_output
â”‚  â””â”€ duration: 8.5s
â”‚
â”œâ”€ Span: curate
â”‚  â”œâ”€ Generation: gpt-4o-mini completion
â”‚  â””â”€ duration: 2.1s
â”‚
â”œâ”€ Span: write (iteration 0)
â”‚  â”œâ”€ Generation: gpt-4o-mini completion
â”‚  â””â”€ duration: 3.2s
â”‚
â”œâ”€ Span: editorial (LLMAgent)
â”‚  â”œâ”€ Span: LlmAgent.run
â”‚  â”‚  â”œâ”€ Generation: planning
â”‚  â”‚  â”œâ”€ Tool Call: check_factual_claims(article, sources)
â”‚  â”‚  â”‚  â””â”€ result: {verified: 2, unverified: 1}
â”‚  â”‚  â”œâ”€ Tool Call: assess_readability(text)
â”‚  â”‚  â”‚  â””â”€ result: {flesch: 45, grade: 12}
â”‚  â”‚  â”œâ”€ Tool Call: verify_sources(sources)
â”‚  â”‚  â”‚  â””â”€ result: {credibility_rate: 0.4}
â”‚  â”‚  â”œâ”€ Generation: decision
â”‚  â”‚  â”œâ”€ Tool Call: suggest_improvements(article, issues)
â”‚  â”‚  â”‚  â””â”€ result: "1. Verify claim...\n2. ..."
â”‚  â”‚  â””â”€ Generation: final_decision
â”‚  â””â”€ duration: 6.8s
â”‚
â”œâ”€ Span: write (iteration 1)  â† Revision
â”‚  â”œâ”€ Generation: gpt-4o-mini completion (with feedback)
â”‚  â””â”€ duration: 3.5s
â”‚
â”œâ”€ Span: editorial (LLMAgent)  â† Second review
â”‚  â”œâ”€ Span: LlmAgent.run
â”‚  â”‚  â”œâ”€ Tool Call: check_factual_claims(revised_article, sources)
â”‚  â”‚  â”‚  â””â”€ result: {verified: 3, unverified: 0}
â”‚  â”‚  â”œâ”€ Tool Call: assess_readability(revised_text)
â”‚  â”‚  â”‚  â””â”€ result: {flesch: 65, grade: 9}
â”‚  â”‚  â””â”€ Generation: approve_decision
â”‚  â””â”€ duration: 4.2s
â”‚
â””â”€ Span: design
   â””â”€ duration: 100ms

Total Duration: ~28s
Tool Calls: 8 (visible in trace)
Revisions: 1 (agent-driven)
```

**Benefits of this trace structure:**
- See exactly which tools were called and why
- Observe agent reasoning process
- Track revision iterations
- Measure time per agent decision
- Debug tool call failures
- Optimize expensive operations

---

## Cost Analysis

**Per Article (estimated)**

| Workflow | Input Tokens | Output Tokens | Tool Calls | Cost |
|----------|-------------|---------------|------------|------|
| Simple | 5,000 | 2,000 | 0 | $0.03 |
| Dynamic | 15,000 | 5,000 | 0 | $0.10 |
| **Agent** | 8,000 | 3,000 | **8** | **$0.06** |

Agent workflow is more cost-effective than Dynamic while providing better quality through autonomous verification.

---

## Key Takeaways

1. **Autonomy**: Agents decide tool usage, not hardcoded logic
2. **Transparency**: All tool calls visible in traces
3. **Quality**: Evidence-based decisions via tools
4. **Flexibility**: Easy to add new tools without changing workflow
5. **ReAct Pattern**: Plan â†’ Act â†’ Observe â†’ Iterate (internal to agent)
6. **Agent-Controlled Loops**: Editorial agent decides revision, not fixed logic

---

## Next Steps

### Extend Research Agent
```python
# Add more tools
tools=[
    web_search,
    extract_key_facts,
    refine_search_query,
    check_source_date,  # NEW: Check if sources are recent
    compare_sources,    # NEW: Compare conflicting info
    summarize_topic     # NEW: Multi-source synthesis
]
```

### Extend Editorial Agent
```python
# Add more verification tools
tools=[
    check_factual_claims,
    assess_readability,
    verify_sources,
    suggest_improvements,
    check_bias,           # NEW: Detect biased language
    verify_statistics,    # NEW: Validate numerical claims
    check_citations       # NEW: Ensure proper attribution
]
```

### Add Coordinator Agent
```python
# Meta-agent that coordinates researcher and editor
coordinator_agent = LlmAgent(
    name="coordinator",
    model="gemini-2.0-flash-exp",
    tools=[
        assign_research_task,
        review_article_status,
        request_revision,
        approve_publication
    ]
)
```
