> # Redis Distributed Workflow Error Analysis and Fix Guide

## Table of Contents

- [Overview](#overview)
- [Error Log](#error-log)
- [Error Analysis](#error-analysis)
  - [Root Cause Analysis](#root-cause-analysis)
  - [Detailed Error Breakdown](#detailed-error-breakdown)
- [Solutions](#solutions)
  - [Option 1: Proper Shutdown Sequence (Recommended)](#option-1-proper-shutdown-sequence-recommended)
  - [Option 2: Add Connection Health Checks](#option-2-add-connection-health-checks)
  - [Option 3: Add Graceful Worker Shutdown](#option-3-add-graceful-worker-shutdown)
  - [Option 4: Use Context Manager Pattern](#option-4-use-context-manager-pattern)
  - [Option 5: Add Redis Connection Pooling](#option-5-add-redis-connection-pooling)
- [Recommended Solution](#recommended-solution)

## Overview

This document analyzes a Redis connection error that occurs during the shutdown sequence of a Redis-based distributed workflow and provides comprehensive solutions to fix the issue.

## Error Log

The following error occurs when stopping a Redis-based distributed workflow:

```
ðŸ§¹ Cleaning up Redis data...
ðŸ§¹ Stopping Redis container...
Error in worker loop: I/O operation on closed file.
Traceback (most recent call last):
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/socket.py", line 65, in _read_from_socket
    data = self._sock.recv(socket_read_size)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/myui/workspace/myui/graflow/graflow/worker/worker.py", line 181, in _worker_loop
    task_spec = self.queue.dequeue()
  File "/Users/myui/workspace/myui/graflow/graflow/queue/redis.py", line 83, in dequeue
    task_id = self.redis_client.lpop(self.queue_key)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/commands/core.py", line 2690, in lpop
    return self.execute_command("LPOP", name)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 634, in _execute_command
    return conn.retry.call_with_retry(
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/retry.py", line 87, in call_with_retry
    return do()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 635, in <lambda>
    lambda: self._send_command_parse_response(
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 606, in _send_command_parse_response
    return self.parse_response(conn, command_name, **options)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 653, in parse_response
    response = connection.read_response()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 644, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/socket.py", line 115, in readline
    self._read_from_socket()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/socket.py", line 90, in _read_from_socket
    buf.seek(current_pos)
ValueError: I/O operation on closed file.

ðŸ›‘ Stopping TaskWorkers...
âœ… Stopped worker-1
âœ… Stopped worker-2
Error in worker loop: Error 61 connecting to localhost:6379. Connection refused.
Traceback (most recent call last):
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 1536, in get_connection
    if connection.can_read() and self.cache is None:
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 622, in can_read
    return self._parser.can_read(timeout)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/base.py", line 140, in can_read
    return self._buffer and self._buffer.can_read(timeout)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/socket.py", line 95, in can_read
    return bool(self.unread_bytes()) or self._read_from_socket(
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/_parsers/socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/retry.py", line 87, in call_with_retry
    return do()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 797, in _connect
    raise err
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/myui/workspace/myui/graflow/graflow/worker/worker.py", line 181, in _worker_loop
    task_spec = self.queue.dequeue()
  File "/Users/myui/workspace/myui/graflow/graflow/queue/redis.py", line 83, in dequeue
    task_id = self.redis_client.lpop(self.queue_key)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/commands/core.py", line 2690, in lpop
    return self.execute_command("LPOP", name)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/utils.py", line 191, in wrapper
    return func(*args, **kwargs)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 1540, in get_connection
    connection.connect()
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "/Users/myui/workspace/myui/graflow/.venv/lib/python3.10/site-packages/redis/connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
```

## Error Analysis

This error occurs during the shutdown sequence of a Redis-based distributed workflow. There are two distinct but related issues happening.

### Root Cause Analysis

#### Primary Issue: Race Condition During Shutdown

1. Redis container is stopped first (ðŸ§¹ Stopping Redis container...)
2. Worker threads are still running and trying to poll Redis for tasks
3. Redis connections become invalid when the server shuts down
4. Workers continue trying to use closed/invalid connections

#### Secondary Issue: Connection State Management

- Workers don't handle Redis server shutdown gracefully
- No proper connection health checks before operations
- Missing graceful shutdown coordination between Redis server and workers

### Detailed Error Breakdown

1. **ValueError: I/O operation on closed file**
   - Redis socket connection is closed/corrupted
   - Worker tries to read from a closed socket buffer
   - Occurs when Redis server terminates while client is reading

2. **OSError: [Errno 9] Bad file descriptor**
   - Socket file descriptor becomes invalid
   - Happens when Redis server closes connections abruptly

3. **ConnectionError: Error 61 connecting to localhost:6379. Connection refused**
   - Workers attempt to reconnect after detecting connection issues
   - Redis server is already stopped, so new connections are refused

## Solutions

### Option 1: Proper Shutdown Sequence (Recommended)

Modify the shutdown sequence to stop workers before Redis:

```python
async def cleanup():
    print("ðŸ›‘ Stopping TaskWorkers...")
    # Stop workers first
    for worker in workers:
        worker.stop()

    # Wait for workers to finish current tasks
    await asyncio.gather(*[worker.wait_for_shutdown() for worker in workers])
    print("âœ… All workers stopped")

    print("ðŸ§¹ Stopping Redis container...")
    # Now safe to stop Redis
    redis_container.stop()
```

### Option 2: Add Connection Health Checks

Implement connection health checking in the worker loop:

```python
# In graflow/worker/worker.py
def _worker_loop(self):
    while self.running:
        try:
            # Check connection health before operations
            if not self._is_redis_healthy():
                if self.running:  # Only log if not shutting down
                    logger.warning("Redis connection unhealthy, retrying...")
                time.sleep(1)
                continue

            task_spec = self.queue.dequeue()
            # ... rest of processing

        except (redis.ConnectionError, redis.TimeoutError, OSError, ValueError) as e:
            if self.running:  # Only log if not shutting down
                logger.error(f"Redis error in worker loop: {e}")
            time.sleep(1)  # Brief pause before retry
        except Exception as e:
            logger.error(f"Unexpected error in worker loop: {e}")
            break

def _is_redis_healthy(self):
    try:
        self.queue.redis_client.ping()
        return True
    except:
        return False
```

### Option 3: Add Graceful Worker Shutdown

Enhance worker shutdown handling:

```python
class TaskWorker:
    def __init__(self):
        self.shutdown_event = threading.Event()

    def stop(self):
        self.running = False
        self.shutdown_event.set()

    def wait_for_shutdown(self, timeout=10):
        """Wait for worker to shut down gracefully"""
        return self.shutdown_event.wait(timeout)

    def _worker_loop(self):
        while self.running:
            try:
                # Use timeout to allow periodic shutdown checks
                task_spec = self.queue.dequeue(timeout=1)
                if task_spec is None:
                    continue

                # Process task...

            except (redis.ConnectionError, OSError, ValueError):
                # Check if we're shutting down
                if not self.running:
                    break
                # Otherwise, handle error...
```

### Option 4: Use Context Manager Pattern

Implement proper resource management:

```python
class RedisWorkflowManager:
    def __enter__(self):
        self.start_redis()
        self.start_workers()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # Proper shutdown order
        self.stop_workers()
        self.stop_redis()

# Usage
with RedisWorkflowManager() as manager:
    # Run workflow
    manager.execute_workflow()
    # Automatic cleanup in correct order
```

### Option 5: Add Redis Connection Pooling

Use connection pooling with health checks:

```python
import redis.connection
from redis import ConnectionPool

# Configure connection pool with retry logic
pool = ConnectionPool(
    host='localhost',
    port=6379,
    db=0,
    retry_on_error=[redis.ConnectionError, redis.TimeoutError],
    health_check_interval=30
)

redis_client = redis.Redis(connection_pool=pool)
```

## Recommended Solution

Implement **Option 1 + Option 2** for the most robust solution:

1. **Fix shutdown sequence** - Stop workers before Redis
2. **Add connection health checks** - Prevent operations on dead connections
3. **Improve error handling** - Distinguish between shutdown and actual errors
4. **Use timeouts** - Prevent indefinite blocking during shutdown

This approach will eliminate both the race condition and provide graceful error handling during normal operation.
